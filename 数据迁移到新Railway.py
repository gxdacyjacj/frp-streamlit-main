"""
FRPé¢„æµ‹å¹³å° - æ•°æ®è¿ç§»è„šæœ¬ï¼ˆç”¨äºæ–°éƒ¨ç½²ï¼‰
å°†ç°æœ‰FRPæ•°æ®è¿ç§»åˆ°æ–°çš„Railwayæ•°æ®åº“

ä½¿ç”¨æ–¹æ³•ï¼š
1. åœ¨Railwayåˆ›å»ºæ–°çš„MySQLæ•°æ®åº“
2. è·å–æ•°æ®åº“è¿æ¥ä¿¡æ¯
3. è¿è¡Œè„šæœ¬æ—¶è¾“å…¥è¿æ¥ä¿¡æ¯
4. é€‰æ‹©æ•°æ®æºï¼ˆCSVæ–‡ä»¶æˆ–åŸæ•°æ®åº“ï¼‰
5. è‡ªåŠ¨å®Œæˆæ•°æ®è¿ç§»

æ”¯æŒçš„æ•°æ®æºï¼š
- ä»CSVæ–‡ä»¶å¯¼å…¥ï¼ˆæ¨èï¼‰
- ä»åŸå§‹æ•°æ®åº“å¯¼å…¥ï¼ˆéœ€è¦è¿æ¥ä¿¡æ¯ï¼‰
"""

import pandas as pd
from sqlalchemy import create_engine, text
import os
import urllib.parse
from datetime import datetime

class FRPDataMigrator:
    def __init__(self):
        self.target_db = None
        self.data_df = None
        
    def get_target_database_config(self):
        """è·å–ç›®æ ‡Railwayæ•°æ®åº“é…ç½®"""
        print("ğŸ” é…ç½®ç›®æ ‡Railwayæ•°æ®åº“")
        print("=" * 50)
        
        host = input("Railwayæ•°æ®åº“ä¸»æœº (ä¾‹: containers-us-west-xxx.railway.app): ")
        port = input("æ•°æ®åº“ç«¯å£ (é»˜è®¤: 3306): ") or "3306"
        user = input("æ•°æ®åº“ç”¨æˆ·å (é€šå¸¸æ˜¯ root): ") or "root"
        password = input("æ•°æ®åº“å¯†ç : ")
        database = input("æ•°æ®åº“åç§° (é€šå¸¸æ˜¯ railway): ") or "railway"
        
        return {
            'host': host,
            'port': int(port),
            'user': user,
            'password': password,
            'database': database
        }
    
    def create_database_connection(self, config):
        """åˆ›å»ºæ•°æ®åº“è¿æ¥"""
        try:
            # URLç¼–ç å¯†ç ä»¥å¤„ç†ç‰¹æ®Šå­—ç¬¦
            encoded_password = urllib.parse.quote_plus(config['password'])
            
            connection_string = (
                f"mysql+pymysql://{config['user']}:{encoded_password}@"
                f"{config['host']}:{config['port']}/{config['database']}"
            )
            
            engine = create_engine(connection_string)
            
            # æµ‹è¯•è¿æ¥
            with engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            
            print(f"âœ… æˆåŠŸè¿æ¥åˆ°æ•°æ®åº“: {config['host']}")
            return engine
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return None
    
    def create_frp_table(self, engine):
        """åœ¨ç›®æ ‡æ•°æ®åº“ä¸­åˆ›å»ºFRPæ•°æ®è¡¨"""
        create_table_sql = """
        CREATE TABLE IF NOT EXISTS research_data (
            id INT AUTO_INCREMENT PRIMARY KEY,
            Fiber_Type VARCHAR(100),
            Matrix_Type VARCHAR(100),
            Environmental_Condition VARCHAR(200),
            Temperature_C DECIMAL(8,2),
            Humidity_percent DECIMAL(5,2),
            pH_Value DECIMAL(4,2),
            Solution_Type VARCHAR(200),
            Concentration_mol_L DECIMAL(10,6),
            Duration_days INT,
            Duration_hours DECIMAL(10,2),
            Tensile_Strength_Retention_percent DECIMAL(5,2),
            Mass_Change_percent DECIMAL(8,4),
            Diameter_Change_percent DECIMAL(8,4),
            Appearance_Change TEXT,
            Test_Method VARCHAR(200),
            Specimen_Preparation VARCHAR(500),
            Reference VARCHAR(1000),
            DOI VARCHAR(200),
            Additional_Notes TEXT,
            Data_Source VARCHAR(200),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            
            INDEX idx_fiber_type (Fiber_Type),
            INDEX idx_temperature (Temperature_C),
            INDEX idx_duration (Duration_days),
            INDEX idx_retention (Tensile_Strength_Retention_percent)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
        """
        
        try:
            with engine.connect() as conn:
                conn.execute(text(create_table_sql))
                conn.commit()
            print("âœ… æ•°æ®è¡¨åˆ›å»ºæˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ æ•°æ®è¡¨åˆ›å»ºå¤±è´¥: {e}")
            return False
    
    def load_data_from_csv(self):
        """ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®"""
        print("\nğŸ“ ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®")
        print("=" * 30)
        
        # æŸ¥æ‰¾å¯èƒ½çš„CSVæ–‡ä»¶
        csv_files = []
        for file in os.listdir('.'):
            if file.endswith('.csv') and any(keyword in file.lower() for keyword in ['research', 'data', 'frp', 'export']):
                csv_files.append(file)
        
        if csv_files:
            print("æ‰¾åˆ°ä»¥ä¸‹CSVæ–‡ä»¶:")
            for i, file in enumerate(csv_files):
                print(f"{i+1}. {file}")
            
            try:
                choice = int(input(f"\nè¯·é€‰æ‹©æ–‡ä»¶ (1-{len(csv_files)}): ")) - 1
                selected_file = csv_files[choice]
            except (ValueError, IndexError):
                selected_file = csv_files[0]
                print(f"ä½¿ç”¨é»˜è®¤æ–‡ä»¶: {selected_file}")
        else:
            selected_file = input("è¯·è¾“å…¥CSVæ–‡ä»¶è·¯å¾„: ")
        
        try:
            df = pd.read_csv(selected_file)
            print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è®°å½•")
            print(f"æ•°æ®åˆ—: {list(df.columns)}")
            return df
        except Exception as e:
            print(f"âŒ CSVæ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return None
    
    def load_data_from_database(self):
        """ä»åŸæ•°æ®åº“åŠ è½½æ•°æ®"""
        print("\nğŸ—„ï¸ ä»åŸæ•°æ®åº“åŠ è½½æ•°æ®")
        print("=" * 30)
        
        source_config = {
            'host': input("åŸæ•°æ®åº“ä¸»æœº (ä¾‹: hopper.proxy.rlwy.net): "),
            'port': int(input("åŸæ•°æ®åº“ç«¯å£ (é»˜è®¤: 3306): ") or "3306"),
            'user': input("åŸæ•°æ®åº“ç”¨æˆ·å: "),
            'password': input("åŸæ•°æ®åº“å¯†ç : "),
            'database': input("åŸæ•°æ®åº“åç§°: ")
        }
        
        source_engine = self.create_database_connection(source_config)
        if not source_engine:
            return None
        
        try:
            # è·å–æ•°æ®
            df = pd.read_sql("SELECT * FROM research_data", source_engine)
            print(f"âœ… æˆåŠŸä»åŸæ•°æ®åº“åŠ è½½ {len(df)} æ¡è®°å½•")
            return df
        except Exception as e:
            print(f"âŒ ä»åŸæ•°æ®åº“åŠ è½½å¤±è´¥: {e}")
            return None
    
    def migrate_data(self, df, target_engine):
        """è¿ç§»æ•°æ®åˆ°ç›®æ ‡æ•°æ®åº“"""
        print(f"\nğŸš€ å¼€å§‹æ•°æ®è¿ç§» ({len(df)} æ¡è®°å½•)")
        print("=" * 40)
        
        try:
            # æ¸…ç†æ•°æ®
            df_clean = df.copy()
            
            # å¤„ç†å¯èƒ½çš„æ•°æ®ç±»å‹é—®é¢˜
            for col in df_clean.columns:
                if df_clean[col].dtype == 'object':
                    df_clean[col] = df_clean[col].astype(str)
                    # é™åˆ¶æ–‡æœ¬é•¿åº¦
                    if col in ['Reference', 'Specimen_Preparation']:
                        df_clean[col] = df_clean[col].str[:500]
                    elif col in ['Additional_Notes', 'Appearance_Change']:
                        df_clean[col] = df_clean[col].str[:1000]
            
            # åˆ†æ‰¹å¯¼å…¥æ•°æ®ï¼ˆæ¯æ¬¡1000æ¡ï¼‰
            batch_size = 1000
            total_batches = (len(df_clean) + batch_size - 1) // batch_size
            
            for i in range(0, len(df_clean), batch_size):
                batch_df = df_clean.iloc[i:i+batch_size]
                batch_num = i // batch_size + 1
                
                print(f"æ­£åœ¨å¯¼å…¥ç¬¬ {batch_num}/{total_batches} æ‰¹ ({len(batch_df)} æ¡è®°å½•)...")
                
                batch_df.to_sql(
                    'research_data', 
                    target_engine, 
                    if_exists='append', 
                    index=False, 
                    method='multi'
                )
                
                print(f"âœ… ç¬¬ {batch_num} æ‰¹å¯¼å…¥å®Œæˆ")
            
            print(f"\nğŸ‰ æ•°æ®è¿ç§»å®Œæˆï¼æ€»å…±è¿ç§» {len(df_clean)} æ¡è®°å½•")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®è¿ç§»å¤±è´¥: {e}")
            return False
    
    def verify_migration(self, target_engine):
        """éªŒè¯æ•°æ®è¿ç§»ç»“æœ"""
        print("\nğŸ” éªŒè¯æ•°æ®è¿ç§»ç»“æœ")
        print("=" * 30)
        
        try:
            with target_engine.connect() as conn:
                result = conn.execute(text("SELECT COUNT(*) as count FROM research_data"))
                count = result.fetchone()[0]
                print(f"âœ… ç›®æ ‡æ•°æ®åº“ä¸­æœ‰ {count} æ¡è®°å½•")
                
                # è·å–ä¸€äº›ç»Ÿè®¡ä¿¡æ¯
                stats_result = conn.execute(text("""
                    SELECT 
                        COUNT(DISTINCT Fiber_Type) as fiber_types,
                        COUNT(DISTINCT Matrix_Type) as matrix_types,
                        AVG(Temperature_C) as avg_temp,
                        MIN(Duration_days) as min_duration,
                        MAX(Duration_days) as max_duration
                    FROM research_data 
                    WHERE Fiber_Type IS NOT NULL
                """))
                
                stats = stats_result.fetchone()
                if stats:
                    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
                    print(f"  - çº¤ç»´ç±»å‹: {stats[0]} ç§")
                    print(f"  - åŸºä½“ç±»å‹: {stats[1]} ç§") 
                    print(f"  - å¹³å‡æ¸©åº¦: {stats[2]:.1f}Â°C" if stats[2] else "  - å¹³å‡æ¸©åº¦: N/A")
                    print(f"  - æŒç»­æ—¶é—´: {stats[3]}-{stats[4]} å¤©" if stats[3] and stats[4] else "  - æŒç»­æ—¶é—´: N/A")
                
                return True
                
        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
            return False
    
    def run_migration(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®è¿ç§»æµç¨‹"""
        print("ğŸš‚ FRPé¢„æµ‹å¹³å°æ•°æ®è¿ç§»å·¥å…·")
        print("=" * 60)
        print(f"è¿ç§»æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        # 1. è·å–ç›®æ ‡æ•°æ®åº“é…ç½®
        target_config = self.get_target_database_config()
        target_engine = self.create_database_connection(target_config)
        
        if not target_engine:
            print("âŒ æ— æ³•è¿æ¥ç›®æ ‡æ•°æ®åº“ï¼Œè¿ç§»ç»ˆæ­¢")
            return False
        
        # 2. åˆ›å»ºæ•°æ®è¡¨
        if not self.create_frp_table(target_engine):
            print("âŒ æ•°æ®è¡¨åˆ›å»ºå¤±è´¥ï¼Œè¿ç§»ç»ˆæ­¢")
            return False
        
        # 3. é€‰æ‹©æ•°æ®æº
        print("\nğŸ“¥ é€‰æ‹©æ•°æ®æº")
        print("1. ä»CSVæ–‡ä»¶å¯¼å…¥ï¼ˆæ¨èï¼‰")
        print("2. ä»åŸæ•°æ®åº“å¯¼å…¥")
        
        choice = input("è¯·é€‰æ‹© (1 æˆ– 2): ").strip()
        
        if choice == "2":
            df = self.load_data_from_database()
        else:
            df = self.load_data_from_csv()
        
        if df is None:
            print("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¿ç§»ç»ˆæ­¢")
            return False
        
        # 4. æ‰§è¡Œæ•°æ®è¿ç§»
        if not self.migrate_data(df, target_engine):
            print("âŒ æ•°æ®è¿ç§»å¤±è´¥")
            return False
        
        # 5. éªŒè¯è¿ç§»ç»“æœ
        if not self.verify_migration(target_engine):
            print("âš ï¸ æ•°æ®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®å®Œæ•´æ€§")
        
        # 6. ç”Ÿæˆé…ç½®æ–‡ä»¶
        self.generate_config_files(target_config)
        
        print("\nğŸ‰ FRPæ•°æ®è¿ç§»å®Œæˆï¼")
        print("ä¸‹ä¸€æ­¥: ä½¿ç”¨ç”Ÿæˆçš„é…ç½®æ–‡ä»¶æ›´æ–°æ‚¨çš„åº”ç”¨è®¾ç½®")
        return True
    
    def generate_config_files(self, db_config):
        """ç”Ÿæˆé…ç½®æ–‡ä»¶"""
        print("\nğŸ“ ç”Ÿæˆé…ç½®æ–‡ä»¶")
        print("=" * 20)
        
        # ç”Ÿæˆ.envæ–‡ä»¶
        env_content = f"""# FRPé¢„æµ‹å¹³å°æ•°æ®åº“é…ç½®
# è¿ç§»å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

DB_HOST={db_config['host']}
DB_PORT={db_config['port']}
DB_USER={db_config['user']}
DB_PASSWORD={db_config['password']}
DB_NAME={db_config['database']}

# åº”ç”¨é…ç½®
SECRET_KEY=your-secret-key-here-{datetime.now().strftime('%Y%m%d')}
"""
        
        with open('.env', 'w', encoding='utf-8') as f:
            f.write(env_content)
        
        # ç”ŸæˆStreamlit Secretsé…ç½®
        secrets_content = f'''DB_HOST = "{db_config['host']}"
DB_PORT = "{db_config['port']}"
DB_NAME = "{db_config['database']}"
DB_USER = "{db_config['user']}"
DB_PASSWORD = "{db_config['password']}"
SECRET_KEY = "your-secret-key-here-{datetime.now().strftime('%Y%m%d')}"'''
        
        with open('streamlit_secrets.toml', 'w', encoding='utf-8') as f:
            f.write(secrets_content)
        
        print("âœ… .env æ–‡ä»¶å·²ç”Ÿæˆ")
        print("âœ… streamlit_secrets.toml æ–‡ä»¶å·²ç”Ÿæˆ")
        print("\nğŸ”‘ è¯·å°† streamlit_secrets.toml çš„å†…å®¹å¤åˆ¶åˆ°Streamlit Cloudçš„Secretsé…ç½®ä¸­")

def main():
    """ä¸»å‡½æ•°"""
    migrator = FRPDataMigrator()
    
    try:
        success = migrator.run_migration()
        if success:
            print("\nâœ¨ è¿ç§»æˆåŠŸå®Œæˆï¼")
        else:
            print("\nâŒ è¿ç§»å¤±è´¥")
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·å–æ¶ˆäº†è¿ç§»è¿‡ç¨‹")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()