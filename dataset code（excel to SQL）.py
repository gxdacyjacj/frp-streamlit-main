import pandas as pd
import mysql.connector
from mysql.connector import Error
import numpy as np
import logging
import os

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'host': 'localhost',
    'port': 3306,
    'user': 'root',
    'password': '666666',  # âš ï¸ è¯·ä¿®æ”¹ä¸ºæ‚¨çš„MySQLå¯†ç 
    'database': 'haigui_database',
    'charset': 'utf8mb4'
}

# Excelæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
EXCEL_FILE_PATH = 'D:/haigui/database 1.xlsx'

# åŸºäºExcelå®é™…ä½ç½®çš„åˆ—åæ˜ å°„ï¼ˆ132ä¸ªå­—æ®µï¼‰
MYSQL_COLUMNS = [
    'feature_name',                    # ä½ç½®1
    'Title',                          # ä½ç½®2
    'Author',                         # ä½ç½®3
    'SCI',                           # ä½ç½®4
    'Journal_or_Conference_name',     # ä½ç½®5
    'Year',                          # ä½ç½®6
    'No_field',                      # ä½ç½®7
    'no_field_secondary',            # ä½ç½®8
    'Fiber_type',                    # ä½ç½®9
    'Fiber_type_detail',             # ä½ç½®10
    'Matrix_type',                   # ä½ç½®11
    'Matrix_type_detail',            # ä½ç½®12
    'glass_transition_temperature',   # ä½ç½®13
    'glass_transition_temperature_run_2', # ä½ç½®14
    'cure_ratio',                    # ä½ç½®15
    'Fiber_content_weight',          # ä½ç½®16
    'Fiber_content_volume',          # ä½ç½®17
    'Void_content',                  # ä½ç½®18
    'diameter',                      # ä½ç½®19
    'average_area',                  # ä½ç½®20
    'nominal_area',                  # ä½ç½®21
    'rib',                          # ä½ç½®22
    'surface_treatment',             # ä½ç½®23
    'Water_absorption_at_saturation', # ä½ç½®24
    'Water_absorption_test_standard', # ä½ç½®25
    'Water_absorption_note',         # ä½ç½®26
    'Brand_name',                    # ä½ç½®27
    'Manufacturer',                  # ä½ç½®28
    'Important_notes',               # ä½ç½®29
    'Notes_of_rebar',               # ä½ç½®30
    'Target_parameter',              # ä½ç½®31
    'note_of_target_parameter',      # ä½ç½®32
    'num_1',                        # ä½ç½®33
    'note_of_number',               # ä½ç½®34
    'Value1_1',                     # ä½ç½®35
    'COV1_1',                       # ä½ç½®36
    'note_of_Value1',               # ä½ç½®37
    'Value2_1',                     # ä½ç½®38
    'COV2_1',                       # ä½ç½®39
    'Value2note_1',                 # ä½ç½®40
    'Value3_1',                     # ä½ç½®41
    'COV3_1',                       # ä½ç½®42
    'Value3note_1',                 # ä½ç½®43
    'SEM_T_BCBT',                   # ä½ç½®44
    'SEM_L_BCBT',                   # ä½ç½®45
    'OTHER_main',                   # ä½ç½®46
    'OTHER1_1',                     # ä½ç½®47
    'FTIR_1',                       # ä½ç½®48
    'note_1',                       # ä½ç½®49
    'temperature',                   # ä½ç½®50
    'note_of_temperature',           # ä½ç½®51
    'time_field',                    # ä½ç½®52
    'note_of_time',                  # ä½ç½®53
    'concrete',                      # ä½ç½®54
    'pH_of_concrete',                # ä½ç½®55
    'strength_of_concrete',          # ä½ç½®56
    'crack',                         # ä½ç½®57
    'cover',                         # ä½ç½®58
    'note_of_concrete',              # ä½ç½®59
    'pH_1',                          # ä½ç½®60
    'pHafter',                       # ä½ç½®61
    'ingredient_1',                  # ä½ç½®62
    'pH_2',                          # ä½ç½®63
    'RH_1',                          # ä½ç½®64
    'ingredient_2',                  # ä½ç½®65
    'note_2',                        # ä½ç½®66
    'Location',                      # ä½ç½®67
    'Effektive_Klimaklassifikation', # ä½ç½®68
    'field_average_humidity',        # ä½ç½®69
    'field_average_temperature',     # ä½ç½®70
    'number_field',                  # ä½ç½®71
    'type_field',                    # ä½ç½®72
    'SolutionorMoisture',            # ä½ç½®73
    'cycle_pH',                      # ä½ç½®74
    'cycle_pH_after',                # ä½ç½®75
    'cycle_ingredient',              # ä½ç½®76
    'temp',                          # ä½ç½®77
    'temp2',                         # ä½ç½®78
    'RH_2',                          # ä½ç½®79
    'RH2',                           # ä½ç½®80
    'OTHER1_2',                      # ä½ç½®81
    'OTHER2_main',                   # ä½ç½®82
    'time_in_cycle',                 # ä½ç½®83
    'note_3',                        # ä½ç½®84
    'UV',                            # ä½ç½®85
    'note_4',                        # ä½ç½®86
    'stress_or_strain',              # ä½ç½®87
    'type_of_load',                  # ä½ç½®88
    'value_load',                    # ä½ç½®89
    'ultimate_tensile_strength',     # ä½ç½®90
    'tensile_modulus',               # ä½ç½®91
    'note_5',                        # ä½ç½®92
    'after_condition',               # ä½ç½®93
    'note_6',                        # ä½ç½®94
    'num_2',                         # ä½ç½®95
    'Value1_2',                      # ä½ç½®96
    'COV1_2',                        # ä½ç½®97
    'Value1note',                    # ä½ç½®98
    'retention1',                    # ä½ç½®99
    'Value2_2',                      # ä½ç½®100
    'COV2_2',                        # ä½ç½®101
    'Value2note_2',                  # ä½ç½®102
    'retention2',                    # ä½ç½®103
    'Value3_2',                      # ä½ç½®104
    'COV3_2',                        # ä½ç½®105
    'Value3note_2',                  # ä½ç½®106
    'retention3',                    # ä½ç½®107
    'num_3',                         # ä½ç½®108
    'water_absorption_ratio',        # ä½ç½®109
    'COV_1',                         # ä½ç½®110
    'note_7',                        # ä½ç½®111
    'num_4',                         # ä½ç½®112
    'glass_transition_temperature_2', # ä½ç½®113
    'run2',                          # ä½ç½®114
    'COV_2',                         # ä½ç½®115
    'cure_ratio_2',                  # ä½ç½®116
    'note_8',                        # ä½ç½®117
    'num_5',                         # ä½ç½®118
    'OTHERS',                        # ä½ç½®119
    'OTHERS_note',                   # ä½ç½®120
    'SEM_T_BCAT',                    # ä½ç½®121
    'SEM_L_BCAT',                    # ä½ç½®122
    'SEM_T_ACBT',                    # ä½ç½®123
    'SEM_L_ACBT',                    # ä½ç½®124
    'SEM_T_ACAT',                    # ä½ç½®125
    'SEM_L_ACAT',                    # ä½ç½®126
    'other_lower',                   # ä½ç½®127
    'other2_final',                  # ä½ç½®128
    'note_9',                        # ä½ç½®129
    'FTIR_2',                        # ä½ç½®130
    'note_10',                       # ä½ç½®131
    'important_note'                 # ä½ç½®132
]

def test_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    try:
        connection = mysql.connector.connect(**DB_CONFIG)
        if connection.is_connected():
            logger.info("âœ… æ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸ")
            connection.close()
            return True
    except Error as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return False

def check_files():
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    logger.info(f"ğŸ“ æ£€æŸ¥æ–‡ä»¶: {EXCEL_FILE_PATH}")
    
    if os.path.exists(EXCEL_FILE_PATH):
        logger.info("âœ… æ‰¾åˆ°Excelæ–‡ä»¶")
        file_size = os.path.getsize(EXCEL_FILE_PATH) / (1024*1024)  # MB
        logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        return True
    else:
        logger.error("âŒ Excelæ–‡ä»¶ä¸å­˜åœ¨")
        logger.error(f"è¯·ç¡®ä¿æ–‡ä»¶ä½äº: {EXCEL_FILE_PATH}")
        return False

def read_excel_data():
    """è¯»å–Excelæ•°æ®"""
    try:
        logger.info("ğŸ“– æ­£åœ¨è¯»å–Excelæ–‡ä»¶...")
        df = pd.read_excel(EXCEL_FILE_PATH, header=3, engine='openpyxl')
        logger.info(f"âœ… Excelè¯»å–æˆåŠŸï¼Œæ•°æ®å½¢çŠ¶: {df.shape}")
        
        # åªå–å‰132åˆ—
        df = df.iloc[:, :132]
        logger.info(f"ä½¿ç”¨å‰132åˆ—ï¼Œè°ƒæ•´åå½¢çŠ¶: {df.shape}")
        
        return df
    except Exception as e:
        logger.error(f"âŒ Excelè¯»å–å¤±è´¥: {e}")
        return None

def clean_data(df):
    """æ¸…ç†æ•°æ®"""
    logger.info("ğŸ§¹ æ­£åœ¨æ¸…ç†æ•°æ®...")
    
    df_clean = df.copy()
    
    # å¤„ç†ç‰¹æ®Šå€¼
    special_values = ['SMD', 'Notreported', 'N/A', '', ' ', 'nan', 'NULL', 'None']
    df_clean = df_clean.replace(special_values, None)
    df_clean = df_clean.replace({np.nan: None})
    
    # å¤„ç†æ•°å€¼å­—æ®µ
    numeric_positions = [5, 18, 34, 35]  # Year, diameter, Value1_1, COV1_1
    for pos in numeric_positions:
        if pos < len(df_clean.columns):
            df_clean.iloc[:, pos] = pd.to_numeric(df_clean.iloc[:, pos], errors='coerce')
    
    # å¤„ç†ç™¾åˆ†æ¯”å­—æ®µ
    retention_positions = [98, 102, 106]  # retention1, retention2, retention3
    for pos in retention_positions:
        if pos < len(df_clean.columns):
            df_clean.iloc[:, pos] = df_clean.iloc[:, pos].astype(str).str.replace('%', '').str.replace('nan', '')
    
    # é™åˆ¶æ–‡æœ¬é•¿åº¦
    for col_idx in range(len(df_clean.columns)):
        if df_clean.iloc[:, col_idx].dtype == 'object':
            df_clean.iloc[:, col_idx] = df_clean.iloc[:, col_idx].astype(str).str[:2000]
            df_clean.iloc[:, col_idx] = df_clean.iloc[:, col_idx].replace('None', None)
    
    logger.info("âœ… æ•°æ®æ¸…ç†å®Œæˆ")
    return df_clean

def insert_data(df):
    """æ’å…¥æ•°æ®åˆ°MySQL"""
    try:
        connection = mysql.connector.connect(**DB_CONFIG)
        cursor = connection.cursor()
        
        # â€”â€” ç¬¬ä¸€æ­¥ï¼šæ¸…ç©ºè¡¨ â€”â€” 
        cursor.execute("TRUNCATE TABLE research_data")
        connection.commit()
        logger.info("ğŸ§¹ å·²æ¸…ç©ºè¡¨ research_dataï¼Œå‡†å¤‡æ’å…¥æ–°æ•°æ®")
        # ä½¿ç”¨æ‰€æœ‰132åˆ—
        columns_str = ', '.join([f"`{col}`" for col in MYSQL_COLUMNS])
        placeholders = ', '.join(['%s'] * len(MYSQL_COLUMNS))
        query = f"INSERT INTO research_data ({columns_str}) VALUES ({placeholders})"
        
        logger.info(f"ğŸ“ å‡†å¤‡æ’å…¥ {len(MYSQL_COLUMNS)} ä¸ªå­—æ®µåˆ° {len(df)} è¡Œæ•°æ®")
        
        # å‡†å¤‡æ•°æ®
        data_rows = []
        for _, row in df.iterrows():
            row_data = []
            for i in range(len(MYSQL_COLUMNS)):
                if i < len(row):
                    value = row.iloc[i]
                    
                    if pd.isna(value) or value is None:
                        row_data.append(None)
                    elif isinstance(value, (int, float)) and not np.isnan(value):
                        row_data.append(value)
                    else:
                        str_value = str(value).strip()
                        if str_value in ['nan', 'None', 'NULL', '', 'SMD', 'Notreported']:
                            row_data.append(None)
                        else:
                            row_data.append(str_value)
                else:
                    row_data.append(None)
            
            data_rows.append(tuple(row_data))
        
        # æ‰¹é‡æ’å…¥
        batch_size = 500
        total_rows = len(data_rows)
        inserted = 0
        
        logger.info(f"ğŸš€ å¼€å§‹æ’å…¥ {total_rows} è¡Œæ•°æ®...")
        
        for i in range(0, total_rows, batch_size):
            batch = data_rows[i:i + batch_size]
            try:
                cursor.executemany(query, batch)
                connection.commit()
                inserted += len(batch)
                
                progress = (inserted / total_rows) * 100
                logger.info(f"ğŸ“Š è¿›åº¦: {inserted}/{total_rows} ({progress:.1f}%)")
                
            except Error as batch_error:
                logger.warning(f"æ‰¹æ¬¡æ’å…¥å¤±è´¥ï¼Œå°è¯•å•è¡Œæ’å…¥: {batch_error}")
                connection.rollback()
                
                for j, row in enumerate(batch):
                    try:
                        cursor.execute(query, row)
                        connection.commit()
                        inserted += 1
                    except Error as single_error:
                        logger.error(f"å•è¡Œæ’å…¥å¤±è´¥ (è¡Œ {i+j+1}): {single_error}")
        
        logger.info(f"âœ… æ•°æ®æ’å…¥å®Œæˆï¼å…±æ’å…¥ {inserted} è¡Œ")
        
        cursor.close()
        connection.close()
        return inserted > 0
        
    except Error as e:
        logger.error(f"âŒ æ•°æ®æ’å…¥å¤±è´¥: {e}")
        return False

def verify_data():
    """éªŒè¯æ’å…¥çš„æ•°æ®"""
    try:
        connection = mysql.connector.connect(**DB_CONFIG)
        cursor = connection.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM research_data")
        count = cursor.fetchone()[0]
        logger.info(f"ğŸ“Š æ•°æ®åº“ä¸­æ€»è®°å½•æ•°: {count}")
        
        # æ˜¾ç¤ºæ ·æœ¬æ•°æ®
        cursor.execute("""
            SELECT Title, Author, Year, Fiber_type 
            FROM research_data 
            WHERE Title IS NOT NULL 
            LIMIT 3
        """)
        
        samples = cursor.fetchall()
        logger.info("ğŸ“‹ æ ·æœ¬æ•°æ®:")
        for i, (title, author, year, fiber) in enumerate(samples, 1):
            title_short = title[:50] + "..." if title and len(title) > 50 else title
            logger.info(f"  {i}. {title_short}")
            logger.info(f"     ä½œè€…: {author} | å¹´ä»½: {year} | çº¤ç»´: {fiber}")
        
        cursor.close()
        connection.close()
        return True
        
    except Error as e:
        logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¯ å¼€å§‹Excelåˆ°MySQLæ•°æ®è¿ç§»")
    logger.info("=" * 70)
    
    # æ­¥éª¤1: æ£€æŸ¥æ–‡ä»¶
    logger.info("æ­¥éª¤1: æ£€æŸ¥Excelæ–‡ä»¶")
    if not check_files():
        return
    
    # æ­¥éª¤2: æµ‹è¯•è¿æ¥
    logger.info("æ­¥éª¤2: æµ‹è¯•æ•°æ®åº“è¿æ¥")
    if not test_connection():
        logger.error("âŒ è¯·æ£€æŸ¥MySQLå¯†ç å’ŒæœåŠ¡çŠ¶æ€")
        return
    
    # æ­¥éª¤3: è¯»å–Excel
    logger.info("æ­¥éª¤3: è¯»å–Excelæ•°æ®")
    df = read_excel_data()
    if df is None:
        return
    
    # æ­¥éª¤4: æ¸…ç†æ•°æ®
    logger.info("æ­¥éª¤4: æ¸…ç†æ•°æ®")
    df_clean = clean_data(df)
    
    # æ­¥éª¤5: æ’å…¥æ•°æ®
    logger.info("æ­¥éª¤5: æ’å…¥æ•°æ®åˆ°MySQL")
    if not insert_data(df_clean):
        logger.error("âŒ æ•°æ®æ’å…¥å¤±è´¥")
        return
    
    # æ­¥éª¤6: éªŒè¯æ•°æ®
    logger.info("æ­¥éª¤6: éªŒè¯æ•°æ®")
    if verify_data():
        logger.info("=" * 70)
        logger.info("ğŸ‰ æ•°æ®è¿ç§»æˆåŠŸå®Œæˆï¼")
        logger.info("ğŸ’¡ æ‚¨ç°åœ¨å¯ä»¥åœ¨MySQL Workbenchä¸­æŸ¥çœ‹å’ŒæŸ¥è¯¢æ•°æ®")

if __name__ == "__main__":
    main()