#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FRPè¶…å‚æ•°ä¼˜åŒ–ä¸»ç¨‹åº
Main Hyperparameter Optimization Script for FRP Models

è¿™æ˜¯FRPé’¢ç­‹è€ä¹…æ€§é¢„æµ‹çš„è¶…å‚æ•°ä¼˜åŒ–ä¸»ç¨‹åºã€‚
ç‚¹å‡»è¿è¡ŒæŒ‰é’®(â–¶ï¸)å³å¯æ‰§è¡Œå®Œæ•´çš„è¶…å‚æ•°ä¼˜åŒ–æµç¨‹ï¼

åŠŸèƒ½ç‰¹ç‚¹:
- 7:2:1æ•°æ®åˆ†å‰² (è®­ç»ƒ:éªŒè¯:æµ‹è¯•)
- ç½‘æ ¼æœç´¢å’Œéšæœºæœç´¢è¶…å‚æ•°ä¼˜åŒ–
- è‡ªåŠ¨æ¨¡å‹é€‰æ‹©å’Œè¯„ä¼°
- è¯¦ç»†çš„ç»“æœæŠ¥å‘Šå’Œä¿å­˜
- æ”¯æŒå¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹
"""

import sys
import os
import time
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# å¯¼å…¥æœ¬åœ°æ¨¡å—
try:
    from data_loader import DataLoader
    from preprocessor import FRPDataPreprocessor
    from model_trainer import ModelTrainer
    from utils import print_model_performance
    from config import config
    print("âœ… æˆåŠŸå¯¼å…¥æ‰€æœ‰æœ¬åœ°æ¨¡å—")
except ImportError as e:
    print(f"âš ï¸ å¯¼å…¥æœ¬åœ°æ¨¡å—å¤±è´¥: {e}")
    print("ä½¿ç”¨å†…ç½®çš„è¶…å‚æ•°ä¼˜åŒ–åŠŸèƒ½")

# æœºå™¨å­¦ä¹ åº“
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

class FRPHyperparameterOptimizer:
    """FRPè¶…å‚æ•°ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.experiment_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = Path("experiments") / f"frp_hyperopt_{self.experiment_id}"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.results = []
        
    def create_comprehensive_demo_data(self, n_samples=1000):
        """åˆ›å»ºå…¨é¢çš„FRPæ¼”ç¤ºæ•°æ®"""
        print("ğŸ¯ åˆ›å»ºç»¼åˆFRPæ•°æ®é›†...")
        
        np.random.seed(42)
        
        # åˆ›å»ºæ›´å…¨é¢çš„ç‰¹å¾æ•°æ®
        data = {
            # ç¯å¢ƒæ¡ä»¶
            'pH_environment': np.random.uniform(4, 14, n_samples),
            'exposure_temperature': np.random.uniform(10, 90, n_samples),
            'exposure_time_hours': np.random.uniform(100, 8760, n_samples),  # æœ€å¤š1å¹´
            'humidity': np.random.uniform(30, 100, n_samples),
            'chloride_concentration': np.random.uniform(0, 5, n_samples),
            
            # ææ–™å±æ€§
            'fiber_content_percent': np.random.uniform(0.5, 8.0, n_samples),
            'fiber_diameter_mm': np.random.uniform(6, 20, n_samples),
            'matrix_strength_mpa': np.random.uniform(400, 1800, n_samples),
            'concrete_strength_mpa': np.random.uniform(20, 80, n_samples),
            
            # å‡ ä½•å’Œè·è½½
            'rebar_diameter_mm': np.random.uniform(8, 32, n_samples),
            'applied_load_percent': np.random.uniform(0, 80, n_samples),
            'cover_thickness_mm': np.random.uniform(20, 80, n_samples),
            
            # åˆ†ç±»ç‰¹å¾
            'fiber_type': np.random.choice([0, 1, 2], n_samples),  # 0:ç»ç’ƒçº¤ç»´, 1:ç¢³çº¤ç»´, 2:èŠ³çº¶çº¤ç»´
            'matrix_type': np.random.choice([0, 1], n_samples),    # 0:ç¯æ°§æ ‘è„‚, 1:ä¹™çƒ¯åŸºé…¯
            'surface_treatment': np.random.choice([0, 1], n_samples),  # 0:æ— , 1:æœ‰
            'loading_type': np.random.choice([0, 1, 2], n_samples),  # 0:é™è½½, 1:ç–²åŠ³, 2:å†²å‡»
        }
        
        df = pd.DataFrame(data)
        
        # åˆ›å»ºå¤æ‚çš„å¤šå› ç´ ç›®æ ‡å˜é‡æ¨¡å‹
        # åŸºç¡€å¼ºåº¦ä¿ç•™ç‡
        base_retention = 0.9
        
        # pHæ•ˆåº” (éçº¿æ€§ï¼Œä¸­æ€§æœ€å¥½)
        ph_effect = -0.02 * (df['pH_environment'] - 8.5) ** 2
        
        # æ¸©åº¦æ•ˆåº” (é«˜æ¸©æœ‰å®³)
        temp_effect = -0.004 * (df['exposure_temperature'] - 20)
        
        # æ—¶é—´æ•ˆåº” (å¯¹æ•°è¡°å‡)
        time_effect = -0.15 * np.log(df['exposure_time_hours'] / 100)
        
        # æ°¯ç¦»å­æ•ˆåº” (çº¿æ€§æœ‰å®³)
        chloride_effect = -0.08 * df['chloride_concentration']
        
        # çº¤ç»´å«é‡æ•ˆåº” (é€‚é‡æœ€ä½³)
        fiber_effect = 0.03 * df['fiber_content_percent'] - 0.002 * df['fiber_content_percent'] ** 2
        
        # è·è½½æ•ˆåº” (é«˜è·è½½æœ‰å®³)
        load_effect = -0.002 * df['applied_load_percent']
        
        # çº¤ç»´ç±»å‹æ•ˆåº” (ç¢³çº¤ç»´>èŠ³çº¶>ç»ç’ƒ)
        fiber_type_effect = np.where(df['fiber_type'] == 1, 0.05,  # ç¢³çº¤ç»´
                                   np.where(df['fiber_type'] == 2, 0.02, 0))  # èŠ³çº¶çº¤ç»´
        
        # è¡¨é¢å¤„ç†æ•ˆåº”
        surface_effect = np.where(df['surface_treatment'] == 1, 0.03, 0)
        
        # ç»¼åˆæ•ˆåº”
        retention = (base_retention + ph_effect + temp_effect + time_effect + 
                    chloride_effect + fiber_effect + load_effect + 
                    fiber_type_effect + surface_effect + 
                    np.random.normal(0, 0.05, n_samples))
        
        # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
        df['tensile_strength_retention'] = np.clip(retention, 0.1, 1.0)
        
        print(f"âœ… ç»¼åˆæ•°æ®é›†åˆ›å»ºå®Œæˆ: {df.shape}")
        print(f"   ç›®æ ‡å˜é‡èŒƒå›´: {df['tensile_strength_retention'].min():.3f} - {df['tensile_strength_retention'].max():.3f}")
        print(f"   ç›®æ ‡å˜é‡å‡å€¼: {df['tensile_strength_retention'].mean():.3f}")
        print(f"   ç›®æ ‡å˜é‡æ ‡å‡†å·®: {df['tensile_strength_retention'].std():.3f}")
        
        return df
    
    def split_data_7_2_1(self, X, y):
        """7:2:1æ•°æ®åˆ†å‰²"""
        # é¦–å…ˆåˆ†å‡º10%ä½œä¸ºæµ‹è¯•é›†
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y, test_size=0.1, random_state=42, stratify=None
        )
        
        # ä»å‰©ä½™90%ä¸­åˆ†å‡ºè®­ç»ƒé›†(77.8%)å’ŒéªŒè¯é›†(22.2%)ï¼Œä½¿å¾—æœ€ç»ˆæ¯”ä¾‹ä¸º7:2:1
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=0.222, random_state=42
        )
        
        return X_train, X_val, X_test, y_train, y_val, y_test
    
    def define_hyperparameter_grids(self):
        """å®šä¹‰è¶…å‚æ•°æœç´¢ç©ºé—´"""
        
        # éšæœºæ£®æ—å‚æ•°ç©ºé—´
        rf_grid = {
            'n_estimators': [50, 100, 200, 300],
            'max_depth': [5, 10, 15, 20, None],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4, 8],
            'max_features': ['sqrt', 'log2', None]
        }
        
        rf_random = {
            'n_estimators': [10, 50, 100, 200, 300, 500],
            'max_depth': [3, 5, 10, 15, 20, 25, None],
            'min_samples_split': [2, 5, 10, 20],
            'min_samples_leaf': [1, 2, 4, 8, 16],
            'max_features': ['sqrt', 'log2', 0.3, 0.5, 0.7, None],
            'bootstrap': [True, False]
        }
        
        return {
            'random_forest': {
                'grid': rf_grid,
                'random': rf_random,
                'model': RandomForestRegressor(random_state=42)
            }
        }
    
    def evaluate_model(self, model, X_test, y_test):
        """æ¨¡å‹è¯„ä¼°"""
        y_pred = model.predict(X_test)
        
        return {
            'r2_score': r2_score(y_test, y_pred),
            'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
            'mae': mean_absolute_error(y_test, y_pred),
            'predictions': y_pred.tolist(),
            'actuals': y_test.tolist()
        }
    
    def run_hyperparameter_search(self, model_name, model_config, X_train, y_train, X_val, y_val):
        """è¿è¡Œè¶…å‚æ•°æœç´¢"""
        
        results = {}
        
        # ç½‘æ ¼æœç´¢
        print(f"\nğŸ” {model_name} - ç½‘æ ¼æœç´¢...")
        start_time = time.time()
        
        grid_search = GridSearchCV(
            model_config['model'],
            model_config['grid'],
            cv=3,
            scoring='r2',
            n_jobs=-1,
            verbose=0
        )
        
        grid_search.fit(X_train, y_train)
        grid_eval = self.evaluate_model(grid_search, X_val, y_val)
        grid_time = time.time() - start_time
        
        results['grid_search'] = {
            'best_params': grid_search.best_params_,
            'best_score': grid_search.best_score_,
            'evaluation': grid_eval,
            'time_seconds': grid_time,
            'model': grid_search.best_estimator_
        }
        
        print(f"   âœ… ç½‘æ ¼æœç´¢å®Œæˆ - RÂ²: {grid_eval['r2_score']:.4f}, è€—æ—¶: {grid_time:.1f}ç§’")
        
        # éšæœºæœç´¢
        print(f"\nğŸ² {model_name} - éšæœºæœç´¢...")
        start_time = time.time()
        
        random_search = RandomizedSearchCV(
            model_config['model'],
            model_config['random'],
            n_iter=50,
            cv=3,
            scoring='r2',
            n_jobs=-1,
            random_state=42,
            verbose=0
        )
        
        random_search.fit(X_train, y_train)
        random_eval = self.evaluate_model(random_search, X_val, y_val)
        random_time = time.time() - start_time
        
        results['random_search'] = {
            'best_params': random_search.best_params_,
            'best_score': random_search.best_score_,
            'evaluation': random_eval,
            'time_seconds': random_time,
            'model': random_search.best_estimator_
        }
        
        print(f"   âœ… éšæœºæœç´¢å®Œæˆ - RÂ²: {random_eval['r2_score']:.4f}, è€—æ—¶: {random_time:.1f}ç§’")
        
        return results
    
    def run_full_optimization(self):
        """è¿è¡Œå®Œæ•´çš„è¶…å‚æ•°ä¼˜åŒ–æµç¨‹"""
        
        print("=" * 70)
        print("ğŸš€ FRPé’¢ç­‹è€ä¹…æ€§é¢„æµ‹ - å®Œæ•´è¶…å‚æ•°ä¼˜åŒ–æµç¨‹")
        print("=" * 70)
        print(f"å®éªŒID: {self.experiment_id}")
        print(f"ç»“æœä¿å­˜ç›®å½•: {self.output_dir}")
        
        # 1. æ•°æ®å‡†å¤‡
        print(f"\nğŸ“Š ç¬¬1æ­¥: æ•°æ®å‡†å¤‡")
        df = self.create_comprehensive_demo_data(n_samples=1500)
        
        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
        feature_cols = [col for col in df.columns if col != 'tensile_strength_retention']
        X = df[feature_cols]
        y = df['tensile_strength_retention']
        
        print(f"   ç‰¹å¾æ•°é‡: {X.shape[1]}")
        print(f"   æ ·æœ¬æ•°é‡: {X.shape[0]}")
        print(f"   ç‰¹å¾åˆ—è¡¨: {list(X.columns)}")
        
        # 2. æ•°æ®åˆ†å‰²
        print(f"\nğŸ”„ ç¬¬2æ­¥: 7:2:1æ•°æ®åˆ†å‰²")
        X_train, X_val, X_test, y_train, y_val, y_test = self.split_data_7_2_1(X, y)
        
        print(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬ ({X_train.shape[0]/len(X)*100:.1f}%)")
        print(f"   éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬ ({X_val.shape[0]/len(X)*100:.1f}%)")
        print(f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬ ({X_test.shape[0]/len(X)*100:.1f}%)")
        
        # 3. è¶…å‚æ•°æœç´¢
        print(f"\nğŸ”§ ç¬¬3æ­¥: è¶…å‚æ•°ä¼˜åŒ–")
        hyperparameter_grids = self.define_hyperparameter_grids()
        
        all_results = {}
        
        for model_name, model_config in hyperparameter_grids.items():
            print(f"\nğŸ“ˆ ä¼˜åŒ–æ¨¡å‹: {model_name}")
            model_results = self.run_hyperparameter_search(
                model_name, model_config, X_train, y_train, X_val, y_val
            )
            all_results[model_name] = model_results
        
        # 4. æœ€ä½³æ¨¡å‹é€‰æ‹©å’Œæµ‹è¯•é›†è¯„ä¼°
        print(f"\nğŸ† ç¬¬4æ­¥: æœ€ä½³æ¨¡å‹é€‰æ‹©å’Œæœ€ç»ˆè¯„ä¼°")
        
        best_overall_r2 = -np.inf
        best_model_info = None
        
        for model_name, model_results in all_results.items():
            for search_type, search_results in model_results.items():
                val_r2 = search_results['evaluation']['r2_score']
                if val_r2 > best_overall_r2:
                    best_overall_r2 = val_r2
                    best_model_info = {
                        'model_name': model_name,
                        'search_type': search_type,
                        'model': search_results['model'],
                        'params': search_results['best_params']
                    }
        
        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹
        if best_model_info:
            final_evaluation = self.evaluate_model(
                best_model_info['model'], X_test, y_test
            )
            
            print(f"\nğŸ¯ æœ€ä½³æ¨¡å‹: {best_model_info['model_name']} ({best_model_info['search_type']})")
            print(f"   éªŒè¯é›†RÂ²: {best_overall_r2:.4f}")
            print(f"   æµ‹è¯•é›†RÂ²: {final_evaluation['r2_score']:.4f}")
            print(f"   æµ‹è¯•é›†RMSE: {final_evaluation['rmse']:.4f}")
            print(f"   æµ‹è¯•é›†MAE: {final_evaluation['mae']:.4f}")
            print(f"   æœ€ä½³å‚æ•°: {best_model_info['params']}")
        
        # 5. ç»“æœæ±‡æ€»å’Œä¿å­˜
        print(f"\nğŸ“‹ ç¬¬5æ­¥: ç»“æœæ±‡æ€»")
        
        summary_data = []
        for model_name, model_results in all_results.items():
            for search_type, search_results in model_results.items():
                eval_results = search_results['evaluation']
                summary_data.append({
                    'æ¨¡å‹': model_name,
                    'æœç´¢æ–¹æ³•': search_type,
                    'éªŒè¯é›†RÂ²': eval_results['r2_score'],
                    'éªŒè¯é›†RMSE': eval_results['rmse'],
                    'éªŒè¯é›†MAE': eval_results['mae'],
                    'è€—æ—¶(ç§’)': search_results['time_seconds'],
                    'æœ€ä½³å‚æ•°': str(search_results['best_params'])
                })
        
        summary_df = pd.DataFrame(summary_data)
        summary_df = summary_df.sort_values('éªŒè¯é›†RÂ²', ascending=False)
        
        print("\nğŸ“Š æ‰€æœ‰å®éªŒç»“æœæ±‡æ€»:")
        print(summary_df.to_string(index=False))
        
        # ä¿å­˜ç»“æœ
        summary_file = self.output_dir / "optimization_summary.csv"
        summary_df.to_csv(summary_file, index=False, encoding='utf-8')
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        detailed_results = {
            'experiment_id': self.experiment_id,
            'timestamp': datetime.now().isoformat(),
            'dataset_info': {
                'total_samples': len(X),
                'features': list(X.columns),
                'train_size': len(X_train),
                'val_size': len(X_val),
                'test_size': len(X_test)
            },
            'best_model': {
                'name': best_model_info['model_name'] if best_model_info else None,
                'search_type': best_model_info['search_type'] if best_model_info else None,
                'params': best_model_info['params'] if best_model_info else None,
                'validation_r2': best_overall_r2,
                'test_evaluation': final_evaluation if best_model_info else None
            },
            'all_results': summary_data
        }
        
        results_file = self.output_dir / "detailed_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, ensure_ascii=False, indent=2, default=str)
        
        # ç‰¹å¾é‡è¦æ€§åˆ†æ
        if best_model_info and hasattr(best_model_info['model'], 'feature_importances_'):
            feature_importance = pd.DataFrame({
                'feature': X.columns,
                'importance': best_model_info['model'].feature_importances_
            }).sort_values('importance', ascending=False)
            
            print(f"\nğŸ” ç‰¹å¾é‡è¦æ€§åˆ†æ (å‰10å):")
            for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):
                print(f"   {i+1:2d}. {row['feature']:<25} {row['importance']:.4f}")
            
            importance_file = self.output_dir / "feature_importance.csv"
            feature_importance.to_csv(importance_file, index=False, encoding='utf-8')
        
        print(f"\nâœ… è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ!")
        print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {self.output_dir}")
        print(f"ğŸ“„ ä¸»è¦æ–‡ä»¶:")
        print(f"   - optimization_summary.csv: ç»“æœæ±‡æ€»è¡¨")
        print(f"   - detailed_results.json: è¯¦ç»†å®éªŒæ•°æ®")
        print(f"   - feature_importance.csv: ç‰¹å¾é‡è¦æ€§")
        print(f"ğŸ“… å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        return detailed_results, self.output_dir

def main():
    """ä¸»å‡½æ•° - ç‚¹å‡»è¿è¡ŒæŒ‰é’®(â–¶ï¸)æ‰§è¡Œæ­¤å‡½æ•°"""
    try:
        print("ğŸš€ å¯åŠ¨FRPè¶…å‚æ•°ä¼˜åŒ–ä¸»ç¨‹åº...")
        
        optimizer = FRPHyperparameterOptimizer()
        results, output_dir = optimizer.run_full_optimization()
        
        print(f"\nğŸ‰ FRPè¶…å‚æ•°ä¼˜åŒ–ä¸»ç¨‹åºæ‰§è¡ŒæˆåŠŸ!")
        print(f"ğŸ† è·å¾—äº†ç»è¿‡å……åˆ†ä¼˜åŒ–çš„FRPè€ä¹…æ€§é¢„æµ‹æ¨¡å‹")
        
    except Exception as e:
        print(f"âŒ ä¸»ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()