# -*- coding: utf-8 -*-
"""
FRP é’¢ç­‹è€ä¹…æ€§é¢„æµ‹ - é¢„æµ‹æ¨¡å—
Prediction Module for FRP Rebar Durability Prediction

åŒ…å«ï¼š
- æ¨¡å‹åŠ è½½
- ç‰¹å¾æ ‡å‡†åŒ–
- é¢„æµ‹åŠŸèƒ½
- ç»“æœè§£é‡Š
"""

import pandas as pd
import numpy as np
import pickle
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Union
import warnings

from .config import config
from .utils import load_model_safely, validate_dataframe
from .preprocessor import FRPDataPreprocessor

class FRPPredictor:
    """FRPè€ä¹…æ€§é¢„æµ‹å™¨ - ç”¨äºåŠ è½½æ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹"""
    
    def __init__(self, model_path: Optional[str] = None):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        """
        self.model = None
        self.feature_info = None
        self.model_metadata = None
        
        if model_path:
            self.load_model(model_path)
    
    def load_model(self, model_path: str) -> bool:
        """
        åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        
        try:
            model_data, additional_info = load_model_safely(model_path)
            
            if model_data is None:
                print(f"âŒ Failed to load model from {model_path}")
                return False
            
            # å¤„ç†ä¸åŒçš„ä¿å­˜æ ¼å¼
            if isinstance(model_data, dict):
                self.model = model_data.get('model')
                self.feature_info = model_data.get('feature_info')
                self.model_metadata = model_data.get('metrics')
            else:
                # å‘åå…¼å®¹ï¼šç›´æ¥æ˜¯æ¨¡å‹å¯¹è±¡
                self.model = model_data
                self.feature_info = additional_info
            
            if self.model is None:
                print(f"âŒ No valid model found in {model_path}")
                return False
            
            print(f"âœ… Model loaded successfully from {model_path}")
            
            # æ‰“å°æ¨¡å‹ä¿¡æ¯
            if self.model_metadata:
                r2_score = self.model_metadata.get('r2', 'Unknown')
                print(f"   Model RÂ² Score: {r2_score}")
            
            if self.feature_info:
                feature_count = len(self.feature_info.get('feature_names', []))
                print(f"   Expected features: {feature_count}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            return False
    
    def standardize_prediction_features(self, input_data: Union[Dict, pd.DataFrame]) -> Optional[np.ndarray]:
        """
        æ ‡å‡†åŒ–é¢„æµ‹è¾“å…¥ç‰¹å¾ï¼Œç¡®ä¿ä¸è®­ç»ƒç‰¹å¾å®Œå…¨ä¸€è‡´
        
        Args:
            input_data: è¾“å…¥æ•°æ®ï¼ˆå­—å…¸æˆ–DataFrameï¼‰
            
        Returns:
            å¤„ç†åçš„ç‰¹å¾æ•°ç»„æˆ–None
        """
        
        if self.model is None:
            print("âŒ No model loaded")
            return None
        
        try:
            # è½¬æ¢ä¸ºDataFrame
            if isinstance(input_data, dict):
                input_df = pd.DataFrame([input_data])
            else:
                input_df = input_data.copy()
            
            # æ£€æŸ¥æ¨¡å‹ç±»å‹
            if hasattr(self.model, 'named_steps'):
                # è¿™æ˜¯ä¸€ä¸ªPipelineï¼Œè®©Pipelineè‡ªå·±å¤„ç†é¢„å¤„ç†
                print("â„¹ï¸ Using Pipeline model - returning DataFrame for Pipeline preprocessing")
                
                # è·å–è®­ç»ƒæ—¶çš„ç‰¹å¾åˆ—
                if self.feature_info and 'feature_names' in self.feature_info:
                    training_columns = self.feature_info['feature_names']
                    
                    # ç¡®ä¿è¾“å…¥åŒ…å«è®­ç»ƒæ—¶ä½¿ç”¨çš„æ‰€æœ‰ç‰¹å¾
                    missing_features = set(training_columns) - set(input_df.columns)
                    if missing_features:
                        print(f"âŒ Missing required features: {list(missing_features)}")
                        return None
                    
                    # åªä¿ç•™è®­ç»ƒæ—¶ä½¿ç”¨çš„ç‰¹å¾ï¼Œå¹¶ä¿æŒæ­£ç¡®é¡ºåº
                    input_df = input_df[training_columns]
                    
                    return input_df  # è¿”å›DataFrameè®©Pipelineå¤„ç†
                else:
                    print("âš ï¸ No training column information found")
                    return input_df
            
            else:
                # è¿™æ˜¯é¢„å¤„ç†è¿‡çš„æ¨¡å‹ï¼Œéœ€è¦æ‰‹åŠ¨å¤„ç†ç‰¹å¾
                print("â„¹ï¸ Using preprocessed model - applying manual feature processing")
                
                if not self.feature_info:
                    print("âŒ No feature information available for preprocessing")
                    return None
                
                # è·å–ç‰¹å¾ä¿¡æ¯
                numeric_features = self.feature_info.get('numeric_features', [])
                categorical_features = self.feature_info.get('categorical_features', [])
                
                # ç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½å­˜åœ¨
                expected_features = numeric_features + categorical_features
                missing_features = set(expected_features) - set(input_df.columns)
                
                if missing_features:
                    print(f"âŒ Missing required features: {list(missing_features)}")
                    return None
                
                # åªä¿ç•™éœ€è¦çš„ç‰¹å¾
                input_df = input_df[expected_features]
                
                print(f"ğŸ” Feature processing:")
                print(f"   - Numeric features: {len(numeric_features)}")
                print(f"   - Categorical features: {len(categorical_features)}")
                
                # è¿™é‡Œéœ€è¦å…·ä½“çš„é¢„å¤„ç†é€»è¾‘ï¼Œå–å†³äºè®­ç»ƒæ—¶ä½¿ç”¨çš„é¢„å¤„ç†å™¨
                # æš‚æ—¶è¿”å›æ•°å€¼éƒ¨åˆ†
                numeric_df = input_df[numeric_features] if numeric_features else pd.DataFrame()
                
                if len(numeric_df.columns) > 0:
                    # ç®€å•çš„æ•°å€¼å¤„ç†
                    numeric_array = numeric_df.fillna(0).values
                    return numeric_array
                else:
                    print("âŒ No numeric features available")
                    return None
        
        except Exception as e:
            print(f"âŒ Feature standardization failed: {e}")
            return None
    
    def predict_single(self, input_data: Union[Dict, pd.DataFrame]) -> Optional[float]:
        """
        å•ä¸ªæ ·æœ¬é¢„æµ‹
        
        Args:
            input_data: è¾“å…¥æ•°æ®
            
        Returns:
            é¢„æµ‹ç»“æœæˆ–None
        """
        
        if self.model is None:
            print("âŒ No model loaded for prediction")
            return None
        
        try:
            # æ ‡å‡†åŒ–ç‰¹å¾
            processed_data = self.standardize_prediction_features(input_data)
            
            if processed_data is None:
                return self._emergency_prediction_fallback(input_data)
            
            # è¿›è¡Œé¢„æµ‹
            if isinstance(processed_data, pd.DataFrame):
                # Pipelineæ¨¡å‹
                prediction = self.model.predict(processed_data)[0]
            else:
                # é¢„å¤„ç†è¿‡çš„æ¨¡å‹
                prediction = self.model.predict(processed_data.reshape(1, -1))[0]
            
            return float(prediction)
            
        except Exception as e:
            print(f"âŒ Prediction failed: {e}")
            return self._emergency_prediction_fallback(input_data)
    
    def predict_batch(self, input_data: pd.DataFrame) -> Optional[np.ndarray]:
        """
        æ‰¹é‡é¢„æµ‹
        
        Args:
            input_data: è¾“å…¥æ•°æ®DataFrame
            
        Returns:
            é¢„æµ‹ç»“æœæ•°ç»„æˆ–None
        """
        
        if self.model is None:
            print("âŒ No model loaded for prediction")
            return None
        
        try:
            validate_dataframe(input_data, name="Input data")
            
            # æ ‡å‡†åŒ–ç‰¹å¾
            processed_data = self.standardize_prediction_features(input_data)
            
            if processed_data is None:
                print("âŒ Feature processing failed for batch prediction")
                return None
            
            # è¿›è¡Œé¢„æµ‹
            if isinstance(processed_data, pd.DataFrame):
                # Pipelineæ¨¡å‹
                predictions = self.model.predict(processed_data)
            else:
                # é¢„å¤„ç†è¿‡çš„æ¨¡å‹
                predictions = self.model.predict(processed_data)
            
            return predictions
            
        except Exception as e:
            print(f"âŒ Batch prediction failed: {e}")
            return None
    
    def _emergency_prediction_fallback(self, input_data: Union[Dict, pd.DataFrame]) -> Optional[float]:
        """
        ç´§æ€¥å¤‡ç”¨é¢„æµ‹åŠŸèƒ½ï¼Œå½“æ ‡å‡†åŒ–å¤±è´¥æ—¶ä½¿ç”¨
        """
        
        try:
            print("ğŸš¨ Using emergency fallback prediction method")
            
            # è½¬æ¢ä¸ºDataFrame
            if isinstance(input_data, dict):
                input_df = pd.DataFrame([input_data])
            else:
                input_df = input_data.copy()
            
            # åªä¿ç•™æ•°å€¼ç‰¹å¾
            numeric_df = input_df.select_dtypes(include=[np.number])
            
            if len(numeric_df.columns) == 0:
                print("âŒ No numeric features found for fallback prediction")
                return None
            
            # ç®€å•æ ‡å‡†åŒ–
            normalized_data = (numeric_df - numeric_df.mean()) / (numeric_df.std() + 1e-8)
            
            # å¡«å……NaN
            normalized_data = normalized_data.fillna(0)
            
            # å°è¯•é¢„æµ‹
            prediction = self.model.predict(normalized_data.values.reshape(1, -1))[0]
            
            print("âš ï¸ Emergency prediction completed (results may be less accurate)")
            return float(prediction)
            
        except Exception as e:
            print(f"âŒ Emergency fallback prediction also failed: {e}")
            return None
    
    def explain_prediction(self, input_data: Union[Dict, pd.DataFrame], 
                          prediction: float) -> Dict[str, Any]:
        """
        è§£é‡Šé¢„æµ‹ç»“æœ
        
        Args:
            input_data: è¾“å…¥æ•°æ®
            prediction: é¢„æµ‹ç»“æœ
            
        Returns:
            è§£é‡Šä¿¡æ¯
        """
        
        explanation = {
            'prediction': prediction,
            'input_summary': {},
            'feature_importance': None,
            'confidence_level': 'Unknown'
        }
        
        # è¾“å…¥æ•°æ®æ‘˜è¦
        if isinstance(input_data, dict):
            explanation['input_summary'] = input_data
        elif isinstance(input_data, pd.DataFrame):
            explanation['input_summary'] = input_data.iloc[0].to_dict()
        
        # é¢„æµ‹ç»“æœè§£é‡Š
        if prediction is not None:
            if prediction >= 0.9:
                explanation['durability_assessment'] = "Excellent"
                explanation['recommendation'] = "Material shows excellent durability characteristics"
            elif prediction >= 0.8:
                explanation['durability_assessment'] = "Good"
                explanation['recommendation'] = "Material has good durability, suitable for most applications"
            elif prediction >= 0.7:
                explanation['durability_assessment'] = "Fair"
                explanation['recommendation'] = "Material durability is acceptable, monitor performance"
            elif prediction >= 0.6:
                explanation['durability_assessment'] = "Poor"
                explanation['recommendation'] = "Material shows reduced durability, consider alternatives"
            else:
                explanation['durability_assessment'] = "Very Poor"
                explanation['recommendation'] = "Material durability is significantly compromised"
        
        return explanation
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        
        info = {
            'model_loaded': self.model is not None,
            'model_type': type(self.model).__name__ if self.model else None,
            'feature_info': self.feature_info,
            'model_metadata': self.model_metadata
        }
        
        return info

class FRPPredictionPipeline:
    """å®Œæ•´çš„FRPé¢„æµ‹ç®¡é“ - ä»åŸå§‹æ•°æ®åˆ°é¢„æµ‹ç»“æœ"""
    
    def __init__(self, model_path: Optional[str] = None):
        """
        åˆå§‹åŒ–é¢„æµ‹ç®¡é“
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        """
        self.preprocessor = FRPDataPreprocessor()
        self.predictor = FRPPredictor(model_path)
    
    def predict_from_raw_data(self, raw_data: Union[Dict, pd.DataFrame]) -> Dict[str, Any]:
        """
        ä»åŸå§‹æ•°æ®è¿›è¡Œå®Œæ•´é¢„æµ‹
        
        Args:
            raw_data: åŸå§‹è¾“å…¥æ•°æ®
            
        Returns:
            é¢„æµ‹ç»“æœå’Œè§£é‡Š
        """
        
        try:
            # è½¬æ¢ä¸ºDataFrame
            if isinstance(raw_data, dict):
                raw_df = pd.DataFrame([raw_data])
            else:
                raw_df = raw_data.copy()
            
            print("ğŸ”„ Processing raw data through preprocessing pipeline...")
            
            # é¢„å¤„ç†
            processed_df = self.preprocessor.preprocess_data(raw_df)
            
            if processed_df is None or len(processed_df) == 0:
                return {
                    'success': False,
                    'error': 'Data preprocessing failed',
                    'prediction': None
                }
            
            # é¢„æµ‹
            prediction = self.predictor.predict_single(processed_df.iloc[0])
            
            if prediction is None:
                return {
                    'success': False,
                    'error': 'Prediction failed',
                    'prediction': None
                }
            
            # è§£é‡Šç»“æœ
            explanation = self.predictor.explain_prediction(processed_df.iloc[0], prediction)
            
            return {
                'success': True,
                'prediction': prediction,
                'explanation': explanation,
                'processed_features': processed_df.iloc[0].to_dict()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'prediction': None
            }

# ä¾¿æ·å‡½æ•°
def load_and_predict(model_path: str, input_data: Union[Dict, pd.DataFrame]) -> Optional[float]:
    """ä¾¿æ·çš„åŠ è½½æ¨¡å‹å¹¶é¢„æµ‹å‡½æ•°"""
    
    predictor = FRPPredictor(model_path)
    if predictor.model is None:
        return None
    
    return predictor.predict_single(input_data)

def create_sample_input() -> Dict[str, Any]:
    """åˆ›å»ºæ ·æœ¬è¾“å…¥æ•°æ®"""
    
    sample_input = {
        'pH_of_condition_enviroment': 7.0,
        'condition_time': 365,  # days
        'fiber_content': 60.0,  # %
        'Temperature': 25.0,  # Â°C
        'diameter': 12.0,  # mm
        'concrete': 0,  # 0=no concrete, 1=concrete
        'load_value': 0.3,  # relative load
        'Chloride_ion': 0,  # 0=no chloride, 1=chloride present
        'Glass_or_Basalt': 1,  # 1=Glass, 0=Basalt
        'Vinyl_ester_or_Epoxy': 1,  # 1=Vinyl ester, 0=Epoxy
        'surface_treatment': 0,  # 0=sand coated, 1=smooth
        'max_strength': 1200.0  # MPa
    }
    
    return sample_input