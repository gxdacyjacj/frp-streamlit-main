#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FRPè¶…å‚æ•°ä¼˜åŒ–å®éªŒè„šæœ¬
Hyperparameter Optimization Experiment Runner for FRP Models

ä½¿ç”¨7:2:1æ•°æ®åˆ†å‰²ç­–ç•¥è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–
"""

import sys
import os
import time
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

try:
    from data_loader import DataLoader
    from preprocessor import FRPDataPreprocessor
    from model_trainer import ModelTrainer
    from utils import print_model_performance
    from config import config
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰æ¨¡å—æ–‡ä»¶å­˜åœ¨ä¸”å¯è®¿é—®")
    sys.exit(1)

class HyperparameterOptimizationExperiment:
    """è¶…å‚æ•°ä¼˜åŒ–å®éªŒç®¡ç†å™¨"""
    
    def __init__(self):
        self.results = []
        self.experiment_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = Path("experiments") / f"hyperopt_{self.experiment_id}"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def create_demo_data(self, n_samples=1000):
        """åˆ›å»ºæ¼”ç¤ºæ•°æ®ç”¨äºè¶…å‚æ•°ä¼˜åŒ–æµ‹è¯•"""
        print("ğŸ¯ åˆ›å»ºæ¼”ç¤ºæ•°æ®è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–æµ‹è¯•...")
        
        np.random.seed(42)
        
        # åˆ›å»ºç‰¹å¾æ•°æ®
        data = {
            'Title': range(n_samples),
            'pH of condition environment': np.random.uniform(5, 12, n_samples),
            'Exposure time': np.random.uniform(100, 2000, n_samples),
            'Fibre content': np.random.uniform(0.1, 5.0, n_samples),
            'Exposure temperature': np.random.uniform(20, 80, n_samples),
            'Diameter': np.random.uniform(6, 16, n_samples),
            'Presence of concrete': np.random.choice([0, 1], n_samples),
            'Load': np.random.uniform(0, 100, n_samples),
            'Presence of chloride ion': np.random.choice([0, 1], n_samples),
            'Fibre type': np.random.choice([0, 1], n_samples),
            'Matrix type': np.random.choice([0, 1], n_samples),
            'Surface treatment': np.random.choice([0, 1], n_samples),
            'Strength of unconditioned rebar': np.random.uniform(500, 1500, n_samples)
        }
        
        # åˆ›å»ºç›®æ ‡å˜é‡ - æ¨¡æ‹ŸçœŸå®å…³ç³»
        df = pd.DataFrame(data)
        
        # æ¨¡æ‹Ÿå¤æ‚çš„éçº¿æ€§å…³ç³»
        ph_effect = (df['pH of condition environment'] - 7) ** 2 * -0.01
        temp_effect = df['Exposure temperature'] * -0.005
        time_effect = np.log(df['Exposure time']) * -0.05
        fiber_effect = df['Fibre content'] * 0.02
        
        base_retention = 0.8
        retention = (base_retention + ph_effect + temp_effect + time_effect + fiber_effect + 
                    np.random.normal(0, 0.1, n_samples))
        
        # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
        retention = np.clip(retention, 0.2, 1.0)
        
        df['Tensile strength retention'] = retention
        
        print(f"âœ… æ¼”ç¤ºæ•°æ®åˆ›å»ºå®Œæˆ: {df.shape}")
        print(f"   ç›®æ ‡å˜é‡èŒƒå›´: {retention.min():.3f} - {retention.max():.3f}")
        print(f"   ç›®æ ‡å˜é‡å‡å€¼: {retention.mean():.3f}")
        
        return df
        
    def define_hyperopt_strategies(self):
        """å®šä¹‰è¶…å‚æ•°ä¼˜åŒ–ç­–ç•¥"""
        
        strategies = [
            {
                'name': 'RandomForest_GridSearch',
                'description': 'éšæœºæ£®æ—ç½‘æ ¼æœç´¢',
                'search_method': 'grid',
                'model_focus': 'random_forest'
            },
            {
                'name': 'RandomForest_RandomSearch', 
                'description': 'éšæœºæ£®æ—éšæœºæœç´¢',
                'search_method': 'random',
                'model_focus': 'random_forest'
            }
        ]
        
        # å¦‚æœæœ‰XGBoostï¼Œæ·»åŠ XGBoostç­–ç•¥
        try:
            import xgboost
            strategies.extend([
                {
                    'name': 'XGBoost_GridSearch',
                    'description': 'XGBoostç½‘æ ¼æœç´¢',
                    'search_method': 'grid',
                    'model_focus': 'xgboost'
                },
                {
                    'name': 'XGBoost_RandomSearch',
                    'description': 'XGBoostéšæœºæœç´¢',
                    'search_method': 'random',
                    'model_focus': 'xgboost'
                }
            ])
        except ImportError:
            print("âš ï¸ XGBoostä¸å¯ç”¨ï¼Œè·³è¿‡XGBoostè¶…å‚æ•°ä¼˜åŒ–")
            
        # å¦‚æœæœ‰LightGBMï¼Œæ·»åŠ LightGBMç­–ç•¥
        try:
            import lightgbm
            strategies.extend([
                {
                    'name': 'LightGBM_GridSearch',
                    'description': 'LightGBMç½‘æ ¼æœç´¢',
                    'search_method': 'grid',
                    'model_focus': 'lightgbm'
                },
                {
                    'name': 'LightGBM_RandomSearch',
                    'description': 'LightGBMéšæœºæœç´¢',
                    'search_method': 'random',
                    'model_focus': 'lightgbm'
                }
            ])
        except ImportError:
            print("âš ï¸ LightGBMä¸å¯ç”¨ï¼Œè·³è¿‡LightGBMè¶…å‚æ•°ä¼˜åŒ–")
        
        return strategies
        
    def run_hyperparameter_optimization(self, df):
        """è¿è¡Œè¶…å‚æ•°ä¼˜åŒ–å®éªŒ"""
        
        strategies = self.define_hyperopt_strategies()
        all_results = []
        
        for i, strategy in enumerate(strategies, 1):
            print(f"\nè¿›åº¦: {i}/{len(strategies)}")
            print("=" * 60)
            print(f"å¼€å§‹å®éªŒ: {strategy['name']}")
            print(f"æè¿°: {strategy['description']}")
            print("=" * 60)
            
            start_time = time.time()
            
            try:
                # ä¸´æ—¶ä¿®æ”¹é…ç½®
                original_method = config.HYPERPARAMETER_SEARCH_METHOD
                original_iter = config.TUNING_N_ITER
                
                config.HYPERPARAMETER_SEARCH_METHOD = strategy['search_method']
                if strategy['search_method'] == 'grid':
                    config.TUNING_N_ITER = 20  # ç½‘æ ¼æœç´¢ç”¨è¾ƒå°‘è¿­ä»£
                else:
                    config.TUNING_N_ITER = 50  # éšæœºæœç´¢ç”¨æ›´å¤šè¿­ä»£
                
                # åˆå§‹åŒ–è®­ç»ƒå™¨ï¼ˆå¯ç”¨è¶…å‚æ•°ä¼˜åŒ–ï¼‰
                trainer = ModelTrainer(enable_hyperparameter_tuning=True)
                
                # åªè®­ç»ƒç‰¹å®šæ¨¡å‹
                target_model = strategy.get('model_focus', 'random_forest')
                if target_model in trainer.models:
                    # è®­ç»ƒå•ä¸ªæ¨¡å‹
                    X, y, feature_info = trainer.prepare_data(df)
                    result = trainer.train_model_with_hyperopt(target_model, X, y)
                    results = {target_model: result}
                else:
                    print(f"âš ï¸ æ¨¡å‹ {target_model} ä¸å¯ç”¨")
                    continue
                
                # æ¢å¤åŸå§‹é…ç½®
                config.HYPERPARAMETER_SEARCH_METHOD = original_method
                config.TUNING_N_ITER = original_iter
                
                end_time = time.time()
                duration = end_time - start_time
                
                if results and target_model in results and 'error' not in results[target_model]:
                    # æ·»åŠ å®éªŒä¿¡æ¯
                    experiment_result = {
                        'strategy_name': strategy['name'],
                        'strategy_description': strategy['description'],
                        'search_method': strategy['search_method'],
                        'model_focus': target_model,
                        'duration_seconds': duration,
                        'model_result': results[target_model],
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    all_results.append(experiment_result)
                    
                    # æ‰“å°ç»“æœ
                    result = results[target_model]
                    if 'r2_score' in result:
                        print(f"âœ… {target_model} è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ!")
                        print(f"   RÂ² åˆ†æ•°: {result['r2_score']:.4f}")
                        print(f"   RMSE: {result.get('rmse', 'N/A'):.4f}")
                        print(f"   è®­ç»ƒé›†: {result.get('train_size', 'N/A')} æ ·æœ¬")
                        print(f"   éªŒè¯é›†: {result.get('val_size', 'N/A')} æ ·æœ¬")
                        print(f"   æµ‹è¯•é›†: {result.get('test_size', 'N/A')} æ ·æœ¬")
                        print(f"â±ï¸ è€—æ—¶: {duration:.1f}ç§’")
                else:
                    print(f"âŒ å®éªŒ {strategy['name']} å¤±è´¥")
                
            except Exception as e:
                print(f"å®éªŒ {strategy['name']} å¤±è´¥: {str(e)}")
                continue
        
        return all_results
    
    def save_experiment_results(self, all_results):
        """ä¿å­˜å®éªŒç»“æœ"""
        
        # ä¿å­˜å®Œæ•´ç»“æœï¼ˆè½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼ï¼‰
        serializable_results = []
        for result in all_results:
            serializable_result = {}
            for key, value in result.items():
                if isinstance(value, (pd.DataFrame, pd.Series)):
                    serializable_result[key] = value.to_dict()
                elif isinstance(value, np.ndarray):
                    serializable_result[key] = value.tolist()
                elif isinstance(value, (np.integer, np.floating)):
                    serializable_result[key] = value.item()
                else:
                    serializable_result[key] = value
            serializable_results.append(serializable_result)
        
        results_file = self.output_dir / "hyperopt_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2, default=str)
        
        # åˆ›å»ºæ±‡æ€»è¡¨
        summary_data = []
        for result in all_results:
            if 'model_result' in result:
                model_result = result['model_result']
                if isinstance(model_result, dict) and 'r2_score' in model_result:
                    summary_data.append({
                        'ç­–ç•¥': result['strategy_name'],
                        'æœç´¢æ–¹æ³•': result['search_method'],
                        'æ¨¡å‹': result.get('model_focus', 'unknown'),
                        'RÂ²': model_result['r2_score'],
                        'RMSE': model_result.get('rmse', 'N/A'),
                        'è®­ç»ƒé›†å¤§å°': model_result.get('train_size', 'N/A'),
                        'éªŒè¯é›†å¤§å°': model_result.get('val_size', 'N/A'),
                        'æµ‹è¯•é›†å¤§å°': model_result.get('test_size', 'N/A'),
                        'è¶…å‚æ•°ä¼˜åŒ–': model_result.get('hyperparameter_optimized', False),
                        'è€—æ—¶(ç§’)': round(result['duration_seconds'], 2)
                    })
        
        if summary_data:
            summary_df = pd.DataFrame(summary_data)
            summary_file = self.output_dir / "hyperopt_summary.csv"
            summary_df.to_csv(summary_file, index=False, encoding='utf-8')
            
            print(f"\nğŸ“Š è¶…å‚æ•°ä¼˜åŒ–ç»“æœæ±‡æ€»:")
            print(summary_df.to_string(index=False))
            
            # æ‰¾åˆ°æœ€ä½³ç»“æœ
            best_idx = summary_df['RÂ²'].idxmax()
            best_result = summary_df.loc[best_idx]
            print(f"\nğŸ† æœ€ä½³ç»“æœ:")
            print(f"   ç­–ç•¥: {best_result['ç­–ç•¥']}")
            print(f"   æ¨¡å‹: {best_result['æ¨¡å‹']}")
            print(f"   RÂ²: {best_result['RÂ²']:.4f}")
            print(f"   RMSE: {best_result['RMSE']:.4f}")
        
        return self.output_dir
    
    def run_all_experiments(self):
        """è¿è¡Œæ‰€æœ‰è¶…å‚æ•°ä¼˜åŒ–å®éªŒ"""
        
        print("FRPé’¢ç­‹è€ä¹…æ€§é¢„æµ‹ - è¶…å‚æ•°ä¼˜åŒ–å®éªŒ")
        print("=" * 50)
        print("ğŸš€ å¼€å§‹FRPè¶…å‚æ•°ä¼˜åŒ–å®éªŒ")
        print(f"å®éªŒID: {self.experiment_id}")
        print(f"ç»“æœä¿å­˜ç›®å½•: {self.output_dir}")
        
        # ä½¿ç”¨æ¼”ç¤ºæ•°æ®ï¼ˆå› ä¸ºåŸå§‹æ•°æ®ç›®æ ‡å˜é‡ä¸ºç©ºï¼‰
        print("\nğŸ“Š å‡†å¤‡æ•°æ®...")
        df = self.create_demo_data(n_samples=1000)
        
        print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"ç›®æ ‡å˜é‡: {df['Tensile strength retention'].describe()}")
        
        start_time = time.time()
        
        # è¿è¡Œè¶…å‚æ•°ä¼˜åŒ–å®éªŒ
        all_results = self.run_hyperparameter_optimization(df)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼æ€»ç”¨æ—¶: {total_time:.1f}ç§’")
        
        # ä¿å­˜ç»“æœ
        output_dir = self.save_experiment_results(all_results)
        
        print(f"\nğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        print(f"\nâœ… è¶…å‚æ•°ä¼˜åŒ–å®éªŒå®Œæˆï¼")
        print(f"è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹: {output_dir}")
        print("- hyperopt_results.json: å®Œæ•´å®éªŒæ•°æ®")
        print("- hyperopt_summary.csv: ç»“æœæ±‡æ€»è¡¨")
        
        return all_results, output_dir

def main():
    """ä¸»å‡½æ•°"""
    try:
        # é…ç½®éªŒè¯
        if hasattr(config, 'validate_config'):
            config.validate_config()
            print("Configuration validation passed")
        
        # è¿è¡Œè¶…å‚æ•°ä¼˜åŒ–å®éªŒ
        experiment = HyperparameterOptimizationExperiment()
        results, output_dir = experiment.run_all_experiments()
        
    except Exception as e:
        print(f"å®éªŒè¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()