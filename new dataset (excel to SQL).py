import pandas as pd
import mysql.connector
from mysql.connector import Error
import numpy as np
import logging
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ•°æ®åº“é…ç½® - æ”¯æŒæœ¬åœ°/Railwayåˆ‡æ¢
def get_db_config():
    """è·å–æ•°æ®åº“é…ç½® - ä¼˜å…ˆä½¿ç”¨Railwayï¼Œå¤‡ç”¨æœ¬åœ°"""
    # æ£€æŸ¥Railwayç¯å¢ƒå˜é‡
    railway_url = os.getenv("DATABASE_URL")
    if railway_url:
        # è§£æRailway URL: mysql://user:pass@host:port/database
        import re
        match = re.match(r'mysql://([^:]+):([^@]+)@([^:]+):(\d+)/(.+)', railway_url)
        if match:
            user, password, host, port, database = match.groups()
            logger.info("ğŸŒ ä½¿ç”¨Railwayæ•°æ®åº“é…ç½®")
            return {
                'host': host,
                'port': int(port),
                'user': user,
                'password': password,
                'database': database,
                'charset': 'utf8mb4'
            }
    
    # å¤‡ç”¨æœ¬åœ°é…ç½®
    logger.info("ğŸ  ä½¿ç”¨æœ¬åœ°æ•°æ®åº“é…ç½®")
    return {
        'host': os.getenv("DB_HOST", "localhost"),
        'port': int(os.getenv("DB_PORT", "3306")),
        'user': os.getenv("DB_USER", "root"),
        'password': os.getenv("DB_PASSWORD", "666666"),
        'database': os.getenv("DB_NAME", "haigui_database"),
        'charset': 'utf8mb4'
    }

# Excelæ–‡ä»¶è·¯å¾„ - database 4.xlsx åœ¨å½“å‰ç›®å½•
EXCEL_FILE_PATH = './database 4.xlsx'

# åŸºäºDatabase 4.xlsxå®é™…ä½ç½®çš„åˆ—åæ˜ å°„ï¼ˆ134ä¸ªå­—æ®µ - åŒ…å«æ–°å¢çš„2ä¸ªå­—æ®µï¼‰
MYSQL_COLUMNS = [
    'feature_name',                    # ä½ç½®1
    'Title',                          # ä½ç½®2
    'Author',                         # ä½ç½®3
    'SCI',                           # ä½ç½®4
    'Journal_or_Conference_name',     # ä½ç½®5
    'Year',                          # ä½ç½®6
    'No_field',                      # ä½ç½®7
    'no_field_secondary',            # ä½ç½®8
    'Fiber_type',                    # ä½ç½®9
    'Fiber_type_detail',             # ä½ç½®10
    'Matrix_type',                   # ä½ç½®11
    'Matrix_type_detail',            # ä½ç½®12
    'glass_transition_temperature',   # ä½ç½®13
    'glass_transition_temperature_run_2', # ä½ç½®14
    'cure_ratio',                    # ä½ç½®15
    'Fiber_content_weight',          # ä½ç½®16
    'Fiber_content_volume',          # ä½ç½®17
    'Void_content',                  # ä½ç½®18
    'diameter',                      # ä½ç½®19
    'average_area',                  # ä½ç½®20
    'nominal_area',                  # ä½ç½®21
    'rib',                          # ä½ç½®22
    'surface_treatment',             # ä½ç½®23
    'Water_absorption_at_saturation', # ä½ç½®24
    'Water_absorption_test_standard', # ä½ç½®25
    'Water_absorption_note',         # ä½ç½®26
    'Brand_name',                    # ä½ç½®27
    'Manufacturer',                  # ä½ç½®28
    'Important_notes',               # ä½ç½®29
    'Notes_of_rebar',               # ä½ç½®30
    'Target_parameter',              # ä½ç½®31
    'note_of_target_parameter',      # ä½ç½®32
    'num_1',                        # ä½ç½®33
    'note_of_number',               # ä½ç½®34
    'Value1_1',                     # ä½ç½®35
    'COV1_1',                       # ä½ç½®36
    'note_of_Value1',               # ä½ç½®37
    'Value2_1',                     # ä½ç½®38
    'COV2_1',                       # ä½ç½®39
    'Value2note_1',                 # ä½ç½®40
    'Value3_1',                     # ä½ç½®41
    'COV3_1',                       # ä½ç½®42
    'Value3note_1',                 # ä½ç½®43
    'SEM_T_BCBT',                   # ä½ç½®44
    'SEM_L_BCBT',                   # ä½ç½®45
    'OTHER_main',                   # ä½ç½®46
    'OTHER1_1',                     # ä½ç½®47
    'FTIR_1',                       # ä½ç½®48
    'note_1',                       # ä½ç½®49
    'temperature',                   # ä½ç½®50
    'note_of_temperature',           # ä½ç½®51
    'time_field',                    # ä½ç½®52
    'note_of_time',                  # ä½ç½®53
    'concrete',                      # ä½ç½®54
    'pH_of_concrete',                # ä½ç½®55
    'strength_of_concrete',          # ä½ç½®56
    'crack',                         # ä½ç½®57
    'cover',                         # ä½ç½®58
    'note_of_concrete',              # ä½ç½®59
    'pH_1',                          # ä½ç½®60
    'pHafter',                       # ä½ç½®61
    'ingredient_1',                  # ä½ç½®62
    'pH_2',                          # ä½ç½®63
    'RH_1',                          # ä½ç½®64
    'ingredient_2',                  # ä½ç½®65
    'note_2',                        # ä½ç½®66
    'Location',                      # ä½ç½®67
    'Effektive_Klimaklassifikation', # ä½ç½®68
    'field_average_humidity',        # ä½ç½®69
    'field_average_temperature',     # ä½ç½®70
    'pH_2_additional',               # ä½ç½®71 â­ æ–°å¢å­—æ®µ1 (database 4ä¸­çš„pH.2)
    'Ingrediant_additional',         # ä½ç½®72 â­ æ–°å¢å­—æ®µ2 (database 4ä¸­çš„Ingrediant)  
    'number_field',                  # ä½ç½®73 (åŸ71)
    'type_field',                    # ä½ç½®74 (åŸ72)
    'SolutionorMoisture',            # ä½ç½®75 (åŸ73)
    'cycle_pH',                      # ä½ç½®76 (åŸ74)
    'cycle_pH_after',                # ä½ç½®77 (åŸ75)
    'cycle_ingredient',              # ä½ç½®78 (åŸ76)
    'temp',                          # ä½ç½®79 (åŸ77)
    'temp2',                         # ä½ç½®80 (åŸ78)
    'RH_2',                          # ä½ç½®81 (åŸ79)
    'RH2',                           # ä½ç½®82 (åŸ80)
    'OTHER1_2',                      # ä½ç½®83 (åŸ81)
    'OTHER2_main',                   # ä½ç½®84 (åŸ82)
    'time_in_cycle',                 # ä½ç½®85 (åŸ83)
    'note_3',                        # ä½ç½®86 (åŸ84)
    'UV',                            # ä½ç½®87 (åŸ85)
    'note_4',                        # ä½ç½®88 (åŸ86)
    'stress_or_strain',              # ä½ç½®89 (åŸ87)
    'type_of_load',                  # ä½ç½®90 (åŸ88)
    'value_load',                    # ä½ç½®91 (åŸ89)
    'ultimate_tensile_strength',     # ä½ç½®92 (åŸ90)
    'tensile_modulus',               # ä½ç½®93 (åŸ91)
    'note_5',                        # ä½ç½®94 (åŸ92)
    'after_condition',               # ä½ç½®95 (åŸ93)
    'note_6',                        # ä½ç½®96 (åŸ94)
    'num_2',                         # ä½ç½®97 (åŸ95)
    'Value1_2',                      # ä½ç½®98 (åŸ96)
    'COV1_2',                        # ä½ç½®99 (åŸ97)
    'Value1note',                    # ä½ç½®100 (åŸ98)
    'retention1',                    # ä½ç½®101 (åŸ99)
    'Value2_2',                      # ä½ç½®102 (åŸ100)
    'COV2_2',                        # ä½ç½®103 (åŸ101)
    'Value2note_2',                  # ä½ç½®104 (åŸ102)
    'retention2',                    # ä½ç½®105 (åŸ103)
    'Value3_2',                      # ä½ç½®106 (åŸ104)
    'COV3_2',                        # ä½ç½®107 (åŸ105)
    'Value3note_2',                  # ä½ç½®108 (åŸ106)
    'retention3',                    # ä½ç½®109 (åŸ107)
    'num_3',                         # ä½ç½®110 (åŸ108)
    'water_absorption_ratio',        # ä½ç½®111 (åŸ109)
    'COV_1',                         # ä½ç½®112 (åŸ110)
    'note_7',                        # ä½ç½®113 (åŸ111)
    'num_4',                         # ä½ç½®114 (åŸ112)
    'glass_transition_temperature_2', # ä½ç½®115 (åŸ113)
    'run2',                          # ä½ç½®116 (åŸ114)
    'COV_2',                         # ä½ç½®117 (åŸ115)
    'cure_ratio_2',                  # ä½ç½®118 (åŸ116)
    'note_8',                        # ä½ç½®119 (åŸ117)
    'num_5',                         # ä½ç½®120 (åŸ118)
    'OTHERS',                        # ä½ç½®121 (åŸ119)
    'OTHERS_note',                   # ä½ç½®122 (åŸ120)
    'SEM_T_BCAT',                    # ä½ç½®123 (åŸ121)
    'SEM_L_BCAT',                    # ä½ç½®124 (åŸ122)
    'SEM_T_ACBT',                    # ä½ç½®125 (åŸ123)
    'SEM_L_ACBT',                    # ä½ç½®126 (åŸ124)
    'SEM_T_ACAT',                    # ä½ç½®127 (åŸ125)
    'SEM_L_ACAT',                    # ä½ç½®128 (åŸ126)
    'other_lower',                   # ä½ç½®129 (åŸ127)
    'other2_final',                  # ä½ç½®130 (åŸ128)
    'note_9',                        # ä½ç½®131 (åŸ129)
    'FTIR_2',                        # ä½ç½®132 (åŸ130)
    'note_10',                       # ä½ç½®133 (åŸ131)
    'important_note'                 # ä½ç½®134 (åŸ132)
]

def test_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    try:
        db_config = get_db_config()
        connection = mysql.connector.connect(**db_config)
        if connection.is_connected():
            logger.info("âœ… æ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸ")
            connection.close()
            return True
    except Error as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return False

def check_files():
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    logger.info(f"ğŸ“ æ£€æŸ¥æ–‡ä»¶: {EXCEL_FILE_PATH}")
    
    if os.path.exists(EXCEL_FILE_PATH):
        logger.info("âœ… æ‰¾åˆ°Excelæ–‡ä»¶")
        file_size = os.path.getsize(EXCEL_FILE_PATH) / (1024*1024)  # MB
        logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        return True
    else:
        logger.error("âŒ Excelæ–‡ä»¶ä¸å­˜åœ¨")
        logger.error(f"è¯·ç¡®ä¿æ–‡ä»¶ä½äº: {EXCEL_FILE_PATH}")
        return False

def read_excel_data():
    """è¯»å–Excelæ•°æ®"""
    try:
        logger.info("ğŸ“– æ­£åœ¨è¯»å–Excelæ–‡ä»¶...")
        df = pd.read_excel(EXCEL_FILE_PATH, header=3, engine='openpyxl')
        logger.info(f"âœ… Excelè¯»å–æˆåŠŸï¼Œæ•°æ®å½¢çŠ¶: {df.shape}")
        
        # å–å‰134åˆ—ï¼ˆé€‚é…database 4.xlsxçš„æ–°ç»“æ„ï¼‰
        df = df.iloc[:, :134]
        logger.info(f"ä½¿ç”¨å‰134åˆ—ï¼ˆåŒ…å«2ä¸ªæ–°å­—æ®µï¼‰ï¼Œè°ƒæ•´åå½¢çŠ¶: {df.shape}")
        
        return df
    except Exception as e:
        logger.error(f"âŒ Excelè¯»å–å¤±è´¥: {e}")
        return None

def clean_data(df):
    """æ¸…ç†æ•°æ®"""
    logger.info("ğŸ§¹ æ­£åœ¨æ¸…ç†æ•°æ®...")
    
    df_clean = df.copy()
    
    # å¤„ç†ç‰¹æ®Šå€¼
    special_values = ['SMD', 'Notreported', 'N/A', '', ' ', 'nan', 'NULL', 'None']
    df_clean = df_clean.replace(special_values, None)
    df_clean = df_clean.replace({np.nan: None})
    
    # å¤„ç†æ•°å€¼å­—æ®µ
    numeric_positions = [5, 18, 34, 35]  # Year, diameter, Value1_1, COV1_1
    for pos in numeric_positions:
        if pos < len(df_clean.columns):
            df_clean.iloc[:, pos] = pd.to_numeric(df_clean.iloc[:, pos], errors='coerce')
    
    # å¤„ç†ç™¾åˆ†æ¯”å­—æ®µ
    retention_positions = [98, 102, 106]  # retention1, retention2, retention3
    for pos in retention_positions:
        if pos < len(df_clean.columns):
            df_clean.iloc[:, pos] = df_clean.iloc[:, pos].astype(str).str.replace('%', '').str.replace('nan', '')
    
    # é™åˆ¶æ–‡æœ¬é•¿åº¦
    for col_idx in range(len(df_clean.columns)):
        if df_clean.iloc[:, col_idx].dtype == 'object':
            df_clean.iloc[:, col_idx] = df_clean.iloc[:, col_idx].astype(str).str[:2000]
            df_clean.iloc[:, col_idx] = df_clean.iloc[:, col_idx].replace('None', None)
    
    logger.info("âœ… æ•°æ®æ¸…ç†å®Œæˆ")
    return df_clean

def create_table(cursor):
    """åˆ›å»ºæ•°æ®è¡¨"""
    # åˆ›å»ºç®€åŒ–è¡¨ç»“æ„ï¼ŒåªåŒ…å«ä¸»è¦å­—æ®µ
    create_table_sql = """
    CREATE TABLE IF NOT EXISTS data (
        id INT AUTO_INCREMENT PRIMARY KEY,
        feature_name VARCHAR(255),
        Title TEXT,
        Author VARCHAR(500),
        SCI VARCHAR(100),
        Journal_or_Conference_name VARCHAR(500),
        Year INT,
        No_field VARCHAR(100),
        no_field_secondary VARCHAR(100),
        Fiber_type VARCHAR(200),
        Fiber_type_detail VARCHAR(500),
        Matrix_type VARCHAR(200),
        Matrix_type_detail VARCHAR(500),
        glass_transition_temperature DECIMAL(10,3),
        glass_transition_temperature_run_2 DECIMAL(10,3),
        cure_ratio DECIMAL(10,3),
        Fiber_content_weight DECIMAL(10,3),
        Fiber_content_volume DECIMAL(10,3),
        Void_content DECIMAL(10,3),
        diameter DECIMAL(10,3),
        average_area DECIMAL(10,3),
        nominal_area DECIMAL(10,3),
        rib VARCHAR(100),
        surface_treatment VARCHAR(200),
        Water_absorption_at_saturation DECIMAL(10,3),
        Water_absorption_test_standard VARCHAR(200),
        Water_absorption_note TEXT,
        Brand_name VARCHAR(200),
        Manufacturer VARCHAR(200),
        Important_notes TEXT,
        Notes_of_rebar TEXT,
        Target_parameter VARCHAR(100),
        note_of_target_parameter TEXT,
        num_1 DECIMAL(10,3),
        note_of_number TEXT,
        Value1_1 DECIMAL(10,3),
        COV1_1 DECIMAL(10,3),
        note_of_Value1 TEXT,
        Value2_1 DECIMAL(10,3),
        COV2_1 DECIMAL(10,3),
        Value2note_1 TEXT,
        Value3_1 DECIMAL(10,3),
        COV3_1 DECIMAL(10,3),
        Value3note_1 TEXT,
        SEM_T_BCBT VARCHAR(100),
        SEM_L_BCBT VARCHAR(100),
        OTHER_main VARCHAR(200),
        OTHER1_1 VARCHAR(200),
        FTIR_1 VARCHAR(200),
        note_1 TEXT,
        temperature DECIMAL(10,3),
        note_of_temperature TEXT,
        time_field DECIMAL(10,3),
        note_of_time TEXT,
        concrete VARCHAR(200),
        pH_of_concrete DECIMAL(10,3),
        strength_of_concrete DECIMAL(10,3),
        crack VARCHAR(100),
        cover DECIMAL(10,3),
        note_of_concrete TEXT,
        pH_1 DECIMAL(10,3),
        pHafter DECIMAL(10,3),
        ingredient_1 VARCHAR(200),
        pH_2 DECIMAL(10,3),
        RH_1 DECIMAL(10,3),
        ingredient_2 VARCHAR(200),
        note_2 TEXT,
        Location VARCHAR(200),
        Effektive_Klimaklassifikation VARCHAR(200),
        field_average_humidity DECIMAL(10,3),
        field_average_temperature DECIMAL(10,3),
        pH_2_additional DECIMAL(10,3),
        Ingrediant_additional VARCHAR(200),
        number_field VARCHAR(100),
        type_field VARCHAR(100),
        SolutionorMoisture VARCHAR(200),
        cycle_pH DECIMAL(10,3),
        cycle_pH_after DECIMAL(10,3),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
    """
    cursor.execute(create_table_sql)
    logger.info("âœ… æ•°æ®è¡¨ç»“æ„åˆ›å»º/éªŒè¯å®Œæˆ")

def insert_data(df):
    """æ’å…¥æ•°æ®åˆ°MySQL"""
    try:
        db_config = get_db_config()
        connection = mysql.connector.connect(**db_config)
        cursor = connection.cursor()
        
        # åˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        create_table(cursor)
        
        # â€”â€” ç¬¬ä¸€æ­¥ï¼šæ¸…ç©ºè¡¨ â€”â€” 
        cursor.execute("TRUNCATE TABLE data")
        connection.commit()
        logger.info("ğŸ§¹ å·²æ¸…ç©ºè¡¨ dataï¼Œå‡†å¤‡æ’å…¥æ–°æ•°æ®")
        
        # ä½¿ç”¨ç®€åŒ–çš„å­—æ®µåˆ—è¡¨ï¼ˆå‰70ä¸ªä¸»è¦å­—æ®µï¼‰
        main_columns = MYSQL_COLUMNS[:70]  # åªä½¿ç”¨å‰70ä¸ªä¸»è¦å­—æ®µ
        columns_str = ', '.join([f"`{col}`" for col in main_columns])
        placeholders = ', '.join(['%s'] * len(main_columns))
        query = f"INSERT INTO data ({columns_str}) VALUES ({placeholders})"
        
        logger.info(f"ğŸ“ å‡†å¤‡æ’å…¥ {len(main_columns)} ä¸ªå­—æ®µåˆ° {len(df)} è¡Œæ•°æ®")
        
        # å‡†å¤‡æ•°æ®
        data_rows = []
        for _, row in df.iterrows():
            row_data = []
            for i in range(len(main_columns)):
                if i < len(row):
                    value = row.iloc[i]
                    
                    if pd.isna(value) or value is None:
                        row_data.append(None)
                    elif isinstance(value, (int, float)) and not np.isnan(value):
                        row_data.append(value)
                    else:
                        str_value = str(value).strip()
                        if str_value in ['nan', 'None', 'NULL', '', 'SMD', 'Notreported']:
                            row_data.append(None)
                        else:
                            row_data.append(str_value)
                else:
                    row_data.append(None)
            
            data_rows.append(tuple(row_data))
        
        # æ‰¹é‡æ’å…¥
        batch_size = 500
        total_rows = len(data_rows)
        inserted = 0
        
        logger.info(f"ğŸš€ å¼€å§‹æ’å…¥ {total_rows} è¡Œæ•°æ®...")
        
        for i in range(0, total_rows, batch_size):
            batch = data_rows[i:i + batch_size]
            try:
                cursor.executemany(query, batch)
                connection.commit()
                inserted += len(batch)
                
                progress = (inserted / total_rows) * 100
                logger.info(f"ğŸ“Š è¿›åº¦: {inserted}/{total_rows} ({progress:.1f}%)")
                
            except Error as batch_error:
                logger.warning(f"æ‰¹æ¬¡æ’å…¥å¤±è´¥ï¼Œå°è¯•å•è¡Œæ’å…¥: {batch_error}")
                connection.rollback()
                
                for j, row in enumerate(batch):
                    try:
                        cursor.execute(query, row)
                        connection.commit()
                        inserted += 1
                    except Error as single_error:
                        logger.error(f"å•è¡Œæ’å…¥å¤±è´¥ (è¡Œ {i+j+1}): {single_error}")
        
        logger.info(f"âœ… æ•°æ®æ’å…¥å®Œæˆï¼å…±æ’å…¥ {inserted} è¡Œ")
        
        cursor.close()
        connection.close()
        return inserted > 0
        
    except Error as e:
        logger.error(f"âŒ æ•°æ®æ’å…¥å¤±è´¥: {e}")
        return False

def verify_data():
    """éªŒè¯æ’å…¥çš„æ•°æ®"""
    try:
        db_config = get_db_config()
        connection = mysql.connector.connect(**db_config)
        cursor = connection.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM data")
        count = cursor.fetchone()[0]
        logger.info(f"ğŸ“Š æ•°æ®åº“ä¸­æ€»è®°å½•æ•°: {count}")
        
        # æ˜¾ç¤ºæ ·æœ¬æ•°æ®
        cursor.execute("""
            SELECT Title, Author, Year, Fiber_type 
            FROM data 
            WHERE Title IS NOT NULL 
            LIMIT 3
        """)
        
        samples = cursor.fetchall()
        logger.info("ğŸ“‹ æ ·æœ¬æ•°æ®:")
        for i, (title, author, year, fiber) in enumerate(samples, 1):
            title_short = title[:50] + "..." if title and len(title) > 50 else title
            logger.info(f"  {i}. {title_short}")
            logger.info(f"     ä½œè€…: {author} | å¹´ä»½: {year} | çº¤ç»´: {fiber}")
        
        cursor.close()
        connection.close()
        return True
        
    except Error as e:
        logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
        return False

def show_env_setup_guide():
    """æ˜¾ç¤ºç¯å¢ƒè®¾ç½®æŒ‡å—"""
    logger.info("ğŸ’¡ æ•°æ®åº“é…ç½®æŒ‡å—:")
    logger.info("=" * 50)
    logger.info("ğŸ“ è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶ï¼Œå†…å®¹å¦‚ä¸‹:")
    logger.info("")
    logger.info("# æœ¬åœ°æ•°æ®åº“é…ç½®")
    logger.info("DB_HOST=localhost")
    logger.info("DB_PORT=3306") 
    logger.info("DB_USER=root")
    logger.info("DB_PASSWORD=ä½ çš„å¯†ç ")
    logger.info("DB_NAME=haigui_database")
    logger.info("")
    logger.info("# Railwayæ•°æ®åº“é…ç½®ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆä½¿ç”¨ï¼‰")
    logger.info("DATABASE_URL=mysql://user:pass@host:port/database")
    logger.info("")
    logger.info("=" * 50)

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¯ å¼€å§‹Excelåˆ°MySQLæ•°æ®è¿ç§» (Database 4.xlsx å…¼å®¹ç‰ˆ)")
    logger.info("=" * 70)
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    db_config = get_db_config()
    current_host = db_config.get('host', 'unknown')
    current_db = db_config.get('database', 'unknown')
    
    # æ­¥éª¤0: æ˜¾ç¤ºå½“å‰é…ç½®
    logger.info("æ­¥éª¤0: å½“å‰æ•°æ®åº“é…ç½®")
    logger.info(f"  ğŸ¯ ç›®æ ‡æ•°æ®åº“: {current_host}:{db_config.get('port', 3306)}")
    logger.info(f"  ğŸ“Š æ•°æ®åº“å: {current_db}")
    logger.info(f"  ğŸ‘¤ ç”¨æˆ·: {db_config.get('user', 'unknown')}")
    
    # æ­¥éª¤1: æ£€æŸ¥æ–‡ä»¶
    logger.info("æ­¥éª¤1: æ£€æŸ¥Excelæ–‡ä»¶")
    if not check_files():
        logger.info("ğŸ“‹ Excelæ–‡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œå¯èƒ½çš„åŸå› :")
        logger.info("  - ç¡®ä¿ database 4.xlsx åœ¨ä¸Šçº§ç›®å½•")
        logger.info("  - æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
        return
    
    # æ­¥éª¤2: æµ‹è¯•è¿æ¥
    logger.info("æ­¥éª¤2: æµ‹è¯•æ•°æ®åº“è¿æ¥")
    if not test_connection():
        logger.error("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥:")
        logger.error("  - MySQLæœåŠ¡æ˜¯å¦å¯åŠ¨")
        logger.error("  - ç”¨æˆ·åå¯†ç æ˜¯å¦æ­£ç¡®")
        logger.error("  - ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ï¼ˆRailwayï¼‰")
        show_env_setup_guide()
        return
    
    # æ­¥éª¤3: è¯»å–Excel
    logger.info("æ­¥éª¤3: è¯»å–Excelæ•°æ® (Database 4.xlsx)")
    df = read_excel_data()
    if df is None:
        return
    
    # æ­¥éª¤4: æ¸…ç†æ•°æ®
    logger.info("æ­¥éª¤4: æ¸…ç†æ•°æ®")
    df_clean = clean_data(df)
    
    # æ­¥éª¤5: æ’å…¥æ•°æ®
    logger.info("æ­¥éª¤5: æ’å…¥æ•°æ®åˆ°MySQL")
    if not insert_data(df_clean):
        logger.error("âŒ æ•°æ®æ’å…¥å¤±è´¥")
        return
    
    # æ­¥éª¤6: éªŒè¯æ•°æ®
    logger.info("æ­¥éª¤6: éªŒè¯æ•°æ®")
    if verify_data():
        logger.info("=" * 70)
        logger.info("ğŸ‰ Database 4.xlsx æ•°æ®è¿ç§»æˆåŠŸå®Œæˆï¼")
        logger.info(f"ğŸ“Š ç›®æ ‡æ•°æ®åº“: {current_host} -> {current_db}")
        logger.info("ğŸ’¡ æ•°æ®å·²åŒ…å«æ–°å¢çš„2ä¸ªå­—æ®µ (pH.2, Ingrediant)")
        logger.info("ğŸ” æ‚¨ç°åœ¨å¯ä»¥åœ¨MySQL Workbenchæˆ–åº”ç”¨ä¸­æŸ¥çœ‹æ•°æ®")

if __name__ == "__main__":
    main()