"""
Database 4.xlsx åˆ° Railway æ•°æ®åº“è¿ç§»è„šæœ¬
ä¸“é—¨ç”¨äºå°† database 4.xlsx æ–‡ä»¶ä¸­çš„æ•°æ®è¿ç§»åˆ°æ–°çš„Railwayæ•°æ®åº“

ä½¿ç”¨æ–¹æ³•ï¼š
1. ç¡®ä¿ database 4.xlsx æ–‡ä»¶åœ¨å½“å‰ç›®å½•
2. å‡†å¤‡å¥½æ–°çš„Railwayæ•°æ®åº“è¿æ¥ä¿¡æ¯
3. è¿è¡Œè„šæœ¬: python database4_to_railway.py
4. æŒ‰æç¤ºè¾“å…¥Railwayæ•°æ®åº“ä¿¡æ¯
5. ç­‰å¾…æ•°æ®è¿ç§»å®Œæˆ

ç‰¹ç‚¹ï¼š
- è‡ªåŠ¨å¤„ç†Excelæ–‡ä»¶çš„å¤æ‚ç»“æ„
- æ”¯æŒ132ä¸ªå­—æ®µçš„å®Œæ•´æ˜ å°„
- åˆ†æ‰¹å¯¼å…¥ï¼Œé¿å…å†…å­˜æº¢å‡º
- è¯¦ç»†çš„è¿›åº¦æ˜¾ç¤ºå’Œé”™è¯¯å¤„ç†
- è‡ªåŠ¨ç”Ÿæˆé…ç½®æ–‡ä»¶ä¾›åº”ç”¨ä½¿ç”¨
"""

import pandas as pd
from sqlalchemy import create_engine, text
import mysql.connector
from mysql.connector import Error
import numpy as np
import logging
import os
import urllib.parse
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Database4ToRailwayMigrator:
    def __init__(self):
        self.excel_file = 'database 4.xlsx'
        self.railway_config = None
        self.railway_engine = None
        
        # Database 4.xlsx çš„132ä¸ªå­—æ®µæ˜ å°„ï¼ˆåŸºäºæ‚¨ç°æœ‰çš„ä»£ç ï¼‰
        self.mysql_columns = [
            'feature_name', 'Title', 'Author', 'SCI', 'Journal_or_Conference_name',
            'Year', 'No_field', 'no_field_secondary', 'Fiber_type', 'Fiber_type_detail',
            'Matrix_type', 'Matrix_type_detail', 'glass_transition_temperature', 
            'glass_transition_temperature_run_2', 'cure_ratio', 'Fiber_content_weight',
            'Fiber_content_volume', 'Void_content', 'diameter', 'average_area',
            'nominal_area', 'rib', 'surface_treatment', 'Water_absorption_at_saturation',
            'Water_absorption_test_standard', 'Water_absorption_note', 'Brand_name',
            'Manufacturer', 'Important_notes', 'Notes_of_rebar', 'Target_parameter',
            'note_of_target_parameter', 'num_1', 'note_of_number', 'Value1_1',
            'COV1_1', 'note_of_Value1', 'Value2_1', 'COV2_1', 'Value2note_1',
            'Value3_1', 'COV3_1', 'Value3note_1', 'SEM_T_BCBT', 'SEM_L_BCBT',
            'OTHER_main', 'OTHER1_1', 'FTIR_1', 'note_1', 'temperature',
            'note_of_temperature', 'time_field', 'note_of_time', 'concrete',
            'pH_of_concrete', 'strength_of_concrete', 'crack', 'cover',
            'note_of_concrete', 'pH_1', 'pHafter', 'ingredient_1', 'pH_2',
            'RH_1', 'ingredient_2', 'note_2', 'Location', 'Effektive_Klimaklassifikation',
            'field_average_humidity', 'field_average_temperature', 'number_field',
            'type_field', 'SolutionorMoisture', 'cycle_pH', 'cycle_pH_after',
            'cycle_ingredient', 'temp', 'temp2', 'RH_2', 'RH2', 'OTHER1_2',
            'OTHER2_main', 'time_in_cycle', 'note_3', 'UV', 'note_4',
            'stress_or_strain', 'type_of_load', 'value_load', 'ultimate_tensile_strength',
            'tensile_modulus', 'note_5', 'after_condition', 'note_6', 'num_2',
            'Value1_2', 'COV1_2', 'Value1note', 'retention1', 'Value2_2',
            'COV2_2', 'Value2note_2', 'retention2', 'Value3_2', 'COV3_2',
            'Value3note_2', 'retention3', 'num_3', 'water_absorption_ratio',
            'COV_1', 'note_7', 'num_4', 'glass_transition_temperature_2',
            'run2', 'COV_2', 'cure_ratio_2', 'note_8', 'num_5', 'OTHERS',
            'OTHERS_note', 'SEM_T_BCAT', 'SEM_L_BCAT', 'SEM_T_ACBT',
            'SEM_L_ACBT', 'SEM_T_ACAT', 'SEM_L_ACAT', 'other_lower',
            'other2_final', 'note_9', 'FTIR_2', 'note_10', 'important_note'
        ]
    
    def check_excel_file(self):
        """æ£€æŸ¥Excelæ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        logger.info(f"ğŸ“ æ£€æŸ¥Excelæ–‡ä»¶: {self.excel_file}")
        
        if os.path.exists(self.excel_file):
            file_size = os.path.getsize(self.excel_file) / (1024*1024)  # MB
            logger.info(f"âœ… æ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {file_size:.2f} MB")
            return True
        else:
            logger.error(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {self.excel_file}")
            logger.error("è¯·ç¡®ä¿ database 4.xlsx æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸­")
            return False
    
    def get_railway_config(self):
        """è·å–Railwayæ•°æ®åº“é…ç½®"""
        print("ğŸš‚ é…ç½®Railwayæ•°æ®åº“è¿æ¥")
        print("=" * 50)
        print("è¯·è¾“å…¥æ‚¨çš„Railwayæ•°æ®åº“è¿æ¥ä¿¡æ¯:")
        print("(å¯ä»¥åœ¨Railwayé¡¹ç›®çš„Variablesé¡µé¢æ‰¾åˆ°è¿™äº›ä¿¡æ¯)")
        print()
        
        host = input("æ•°æ®åº“ä¸»æœº (ä¾‹: containers-us-west-xxx.railway.app): ").strip()
        port = input("æ•°æ®åº“ç«¯å£ (é»˜è®¤: 3306): ").strip() or "3306"
        user = input("æ•°æ®åº“ç”¨æˆ·å (é€šå¸¸æ˜¯ root): ").strip() or "root"
        password = input("æ•°æ®åº“å¯†ç : ").strip()
        database = input("æ•°æ®åº“åç§° (é€šå¸¸æ˜¯ railway): ").strip() or "railway"
        
        self.railway_config = {
            'host': host,
            'port': int(port),
            'user': user,
            'password': password,
            'database': database
        }
        
        return self.railway_config
    
    def test_railway_connection(self):
        """æµ‹è¯•Railwayæ•°æ®åº“è¿æ¥"""
        logger.info("ğŸ”Œ æµ‹è¯•Railwayæ•°æ®åº“è¿æ¥...")
        
        try:
            # ä½¿ç”¨mysql.connectoræµ‹è¯•è¿æ¥
            connection = mysql.connector.connect(
                host=self.railway_config['host'],
                port=self.railway_config['port'],
                user=self.railway_config['user'],
                password=self.railway_config['password'],
                database=self.railway_config['database'],
                charset='utf8mb4'
            )
            
            if connection.is_connected():
                logger.info("âœ… Railwayæ•°æ®åº“è¿æ¥æˆåŠŸ")
                connection.close()
                
                # åˆ›å»ºSQLAlchemyå¼•æ“
                encoded_password = urllib.parse.quote_plus(self.railway_config['password'])
                connection_string = (
                    f"mysql+pymysql://{self.railway_config['user']}:{encoded_password}@"
                    f"{self.railway_config['host']}:{self.railway_config['port']}/{self.railway_config['database']}"
                )
                
                self.railway_engine = create_engine(connection_string)
                return True
            
        except Error as e:
            logger.error(f"âŒ Railwayæ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    def create_research_data_table(self):
        """åœ¨Railwayæ•°æ®åº“ä¸­åˆ›å»ºresearch_dataè¡¨"""
        logger.info("ğŸ”¨ åˆ›å»ºresearch_dataè¡¨...")
        
        # ç”Ÿæˆåˆ›å»ºè¡¨çš„SQLï¼ˆåŸºäº132ä¸ªå­—æ®µï¼‰
        create_table_sql = f"""
        CREATE TABLE IF NOT EXISTS research_data (
            id INT AUTO_INCREMENT PRIMARY KEY,
            {', '.join([f'`{col}` TEXT' for col in self.mysql_columns])},
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            
            INDEX idx_title (Title(100)),
            INDEX idx_author (Author(100)),
            INDEX idx_year (Year(10)),
            INDEX idx_fiber_type (Fiber_type(50)),
            INDEX idx_matrix_type (Matrix_type(50))
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
        """
        
        try:
            with self.railway_engine.connect() as conn:
                conn.execute(text(create_table_sql))
                conn.commit()
            
            logger.info("âœ… research_dataè¡¨åˆ›å»ºæˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºè¡¨å¤±è´¥: {e}")
            return False
    
    def read_excel_data(self):
        """è¯»å–database 4.xlsxæ•°æ®"""
        logger.info("ğŸ“– è¯»å–Excelæ–‡ä»¶æ•°æ®...")
        
        try:
            # ä»ç¬¬4è¡Œå¼€å§‹è¯»å–ï¼ˆè·³è¿‡æ ‡é¢˜è¡Œï¼‰
            df = pd.read_excel(self.excel_file, header=3, engine='openpyxl')
            logger.info(f"âœ… Excelè¯»å–æˆåŠŸï¼ŒåŸå§‹å½¢çŠ¶: {df.shape}")
            
            # åªå–å‰132åˆ—ï¼ŒåŒ¹é…å­—æ®µæ˜ å°„
            df = df.iloc[:, :132]
            logger.info(f"è°ƒæ•´åå½¢çŠ¶: {df.shape}")
            
            # è®¾ç½®åˆ—å
            df.columns = self.mysql_columns
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ Excelè¯»å–å¤±è´¥: {e}")
            return None
    
    def clean_data(self, df):
        """æ¸…ç†æ•°æ®"""
        logger.info("ğŸ§¹ æ¸…ç†æ•°æ®...")
        
        df_clean = df.copy()
        
        # å¤„ç†ç‰¹æ®Šå€¼
        special_values = ['SMD', 'Notreported', 'N/A', '', ' ', 'nan', 'NULL', 'None']
        df_clean = df_clean.replace(special_values, None)
        df_clean = df_clean.replace({np.nan: None})
        
        # å¤„ç†æ•°å€¼å­—æ®µï¼ˆYearç­‰ï¼‰
        numeric_columns = ['Year', 'diameter', 'Value1_1', 'COV1_1']
        for col in numeric_columns:
            if col in df_clean.columns:
                df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
        
        # å¤„ç†ç™¾åˆ†æ¯”å­—æ®µ
        retention_columns = ['retention1', 'retention2', 'retention3']
        for col in retention_columns:
            if col in df_clean.columns:
                df_clean[col] = df_clean[col].astype(str).str.replace('%', '').str.replace('nan', '')
        
        # é™åˆ¶æ–‡æœ¬é•¿åº¦ï¼Œé¿å…æ•°æ®åº“é”™è¯¯
        text_columns = df_clean.select_dtypes(include=['object']).columns
        for col in text_columns:
            df_clean[col] = df_clean[col].astype(str).str[:2000]
            df_clean[col] = df_clean[col].replace('None', None)
        
        logger.info("âœ… æ•°æ®æ¸…ç†å®Œæˆ")
        logger.info(f"æ¸…ç†åæ•°æ®å½¢çŠ¶: {df_clean.shape}")
        
        return df_clean
    
    def migrate_data_to_railway(self, df):
        """å°†æ•°æ®è¿ç§»åˆ°Railwayæ•°æ®åº“"""
        logger.info(f"ğŸš€ å¼€å§‹è¿ç§»æ•°æ®åˆ°Railway ({len(df)} æ¡è®°å½•)")
        
        try:
            # æ¸…ç©ºç°æœ‰æ•°æ®
            with self.railway_engine.connect() as conn:
                conn.execute(text("TRUNCATE TABLE research_data"))
                conn.commit()
            
            logger.info("ğŸ§¹ å·²æ¸…ç©ºè¡¨ï¼Œå¼€å§‹æ’å…¥æ–°æ•°æ®")
            
            # åˆ†æ‰¹æ’å…¥æ•°æ®
            batch_size = 100  # Railwayå¯èƒ½å¯¹æ‰¹æ¬¡å¤§å°æœ‰é™åˆ¶
            total_batches = (len(df) + batch_size - 1) // batch_size
            inserted_count = 0
            
            for i in range(0, len(df), batch_size):
                batch_df = df.iloc[i:i+batch_size].copy()
                batch_num = i // batch_size + 1
                
                logger.info(f"ğŸ“Š æ’å…¥ç¬¬ {batch_num}/{total_batches} æ‰¹ ({len(batch_df)} æ¡è®°å½•)...")
                
                try:
                    batch_df.to_sql(
                        'research_data', 
                        self.railway_engine, 
                        if_exists='append', 
                        index=False, 
                        method='multi'
                    )
                    
                    inserted_count += len(batch_df)
                    progress = (inserted_count / len(df)) * 100
                    logger.info(f"âœ… ç¬¬ {batch_num} æ‰¹æ’å…¥æˆåŠŸï¼Œæ€»è¿›åº¦: {progress:.1f}%")
                    
                except Exception as batch_error:
                    logger.warning(f"âš ï¸ æ‰¹æ¬¡æ’å…¥å¤±è´¥ï¼Œå°è¯•é€è¡Œæ’å…¥: {batch_error}")
                    
                    # é€è¡Œæ’å…¥
                    for _, row in batch_df.iterrows():
                        try:
                            row_df = pd.DataFrame([row])
                            row_df.to_sql(
                                'research_data', 
                                self.railway_engine, 
                                if_exists='append', 
                                index=False
                            )
                            inserted_count += 1
                        except Exception as row_error:
                            logger.error(f"âŒ å•è¡Œæ’å…¥å¤±è´¥: {row_error}")
            
            logger.info(f"ğŸ‰ æ•°æ®è¿ç§»å®Œæˆï¼æˆåŠŸæ’å…¥ {inserted_count} æ¡è®°å½•")
            return inserted_count > 0
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®è¿ç§»å¤±è´¥: {e}")
            return False
    
    def verify_migration(self):
        """éªŒè¯æ•°æ®è¿ç§»ç»“æœ"""
        logger.info("ğŸ” éªŒè¯è¿ç§»ç»“æœ...")
        
        try:
            with self.railway_engine.connect() as conn:
                # æ£€æŸ¥æ€»è®°å½•æ•°
                result = conn.execute(text("SELECT COUNT(*) as count FROM research_data"))
                count = result.fetchone()[0]
                logger.info(f"ğŸ“Š Railwayæ•°æ®åº“ä¸­å…±æœ‰ {count} æ¡è®°å½•")
                
                # è·å–æ ·æœ¬æ•°æ®
                sample_result = conn.execute(text("""
                    SELECT Title, Author, Year, Fiber_type, Matrix_type 
                    FROM research_data 
                    WHERE Title IS NOT NULL 
                    LIMIT 3
                """))
                
                samples = sample_result.fetchall()
                logger.info("ğŸ“‹ æ ·æœ¬æ•°æ®:")
                for i, (title, author, year, fiber, matrix) in enumerate(samples, 1):
                    title_short = title[:50] + "..." if title and len(title) > 50 else title
                    logger.info(f"  {i}. {title_short}")
                    logger.info(f"     ä½œè€…: {author} | å¹´ä»½: {year}")
                    logger.info(f"     çº¤ç»´: {fiber} | åŸºä½“: {matrix}")
                
                # ç»Ÿè®¡ä¿¡æ¯
                stats_result = conn.execute(text("""
                    SELECT 
                        COUNT(DISTINCT Fiber_type) as fiber_types,
                        COUNT(DISTINCT Matrix_type) as matrix_types,
                        COUNT(DISTINCT Author) as authors,
                        MIN(Year) as min_year,
                        MAX(Year) as max_year
                    FROM research_data 
                    WHERE Fiber_type IS NOT NULL OR Matrix_type IS NOT NULL
                """))
                
                stats = stats_result.fetchone()
                if stats:
                    logger.info(f"ğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
                    logger.info(f"  - çº¤ç»´ç±»å‹: {stats[0]} ç§")
                    logger.info(f"  - åŸºä½“ç±»å‹: {stats[1]} ç§")
                    logger.info(f"  - ä½œè€…æ•°é‡: {stats[2]} äºº")
                    logger.info(f"  - å¹´ä»½èŒƒå›´: {stats[3]}-{stats[4]}")
                
                return True
                
        except Exception as e:
            logger.error(f"âŒ éªŒè¯å¤±è´¥: {e}")
            return False
    
    def generate_config_files(self):
        """ç”Ÿæˆé…ç½®æ–‡ä»¶"""
        logger.info("ğŸ“ ç”Ÿæˆåº”ç”¨é…ç½®æ–‡ä»¶...")
        
        # ç”Ÿæˆ.envæ–‡ä»¶
        env_content = f"""# FRPé¢„æµ‹å¹³å°æ•°æ®åº“é…ç½®
# Database 4.xlsx è¿ç§»åˆ°Railwayå®Œæˆ
# è¿ç§»æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

DB_HOST={self.railway_config['host']}
DB_PORT={self.railway_config['port']}
DB_USER={self.railway_config['user']}
DB_PASSWORD={self.railway_config['password']}
DB_NAME={self.railway_config['database']}

# åº”ç”¨é…ç½®
SECRET_KEY=frp-railway-{datetime.now().strftime('%Y%m%d')}-secret
"""
        
        with open('.env', 'w', encoding='utf-8') as f:
            f.write(env_content)
        
        # ç”ŸæˆStreamlit Cloud Secretsé…ç½®
        secrets_content = f'''DB_HOST = "{self.railway_config['host']}"
DB_PORT = "{self.railway_config['port']}"
DB_NAME = "{self.railway_config['database']}"
DB_USER = "{self.railway_config['user']}"
DB_PASSWORD = "{self.railway_config['password']}"
SECRET_KEY = "frp-railway-{datetime.now().strftime('%Y%m%d')}-secret"'''
        
        with open('railway_streamlit_secrets.toml', 'w', encoding='utf-8') as f:
            f.write(secrets_content)
        
        logger.info("âœ… .env æ–‡ä»¶å·²ç”Ÿæˆ")
        logger.info("âœ… railway_streamlit_secrets.toml æ–‡ä»¶å·²ç”Ÿæˆ")
        logger.info("ğŸ“‹ è¯·å°† railway_streamlit_secrets.toml çš„å†…å®¹å¤åˆ¶åˆ°Streamlit Cloudçš„Secretsé…ç½®ä¸­")
    
    def run_migration(self):
        """è¿è¡Œå®Œæ•´çš„è¿ç§»æµç¨‹"""
        print("ğŸš‚ Database 4.xlsx åˆ° Railway æ•°æ®è¿ç§»å·¥å…·")
        print("=" * 70)
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        # æ­¥éª¤1: æ£€æŸ¥Excelæ–‡ä»¶
        if not self.check_excel_file():
            return False
        
        # æ­¥éª¤2: è·å–Railwayé…ç½®
        self.get_railway_config()
        
        # æ­¥éª¤3: æµ‹è¯•Railwayè¿æ¥
        if not self.test_railway_connection():
            logger.error("âŒ è¯·æ£€æŸ¥Railwayæ•°æ®åº“è¿æ¥ä¿¡æ¯")
            return False
        
        # æ­¥éª¤4: åˆ›å»ºæ•°æ®è¡¨
        if not self.create_research_data_table():
            return False
        
        # æ­¥éª¤5: è¯»å–Excelæ•°æ®
        df = self.read_excel_data()
        if df is None:
            return False
        
        # æ­¥éª¤6: æ¸…ç†æ•°æ®
        df_clean = self.clean_data(df)
        
        # æ­¥éª¤7: è¿ç§»æ•°æ®
        if not self.migrate_data_to_railway(df_clean):
            return False
        
        # æ­¥éª¤8: éªŒè¯ç»“æœ
        if not self.verify_migration():
            logger.warning("âš ï¸ éªŒè¯å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥æ•°æ®")
        
        # æ­¥éª¤9: ç”Ÿæˆé…ç½®æ–‡ä»¶
        self.generate_config_files()
        
        print("\n" + "=" * 70)
        print("ğŸ‰ Database 4.xlsx è¿ç§»åˆ°RailwayæˆåŠŸå®Œæˆï¼")
        print()
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("  â”œâ”€â”€ .env (æœ¬åœ°å¼€å‘é…ç½®)")
        print("  â””â”€â”€ railway_streamlit_secrets.toml (Streamlit Cloudé…ç½®)")
        print()
        print("ğŸ”„ ä¸‹ä¸€æ­¥:")
        print("1. ä½¿ç”¨ .env æ–‡ä»¶è¿›è¡Œæœ¬åœ°æµ‹è¯•")
        print("2. å°† railway_streamlit_secrets.toml å†…å®¹å¤åˆ¶åˆ°Streamlit Cloud")
        print("3. é‡æ–°éƒ¨ç½²æ‚¨çš„åº”ç”¨")
        print()
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    migrator = Database4ToRailwayMigrator()
    
    try:
        success = migrator.run_migration()
        if success:
            print("âœ¨ è¿ç§»æˆåŠŸï¼æ‚¨çš„Database 4.xlsxæ•°æ®ç°åœ¨å·²åœ¨Railwayäº‘æ•°æ®åº“ä¸­")
        else:
            print("âŒ è¿ç§»å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡è¯•")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·å–æ¶ˆäº†è¿ç§»è¿‡ç¨‹")
    except Exception as e:
        logger.error(f"âŒ å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")

if __name__ == "__main__":
    main()